[{"content":"Introduction This tutorial will show you how to use @ConfigurationProperties in a Spring Boot application. This annotation is designed to load properties from an application property file into an application context and configure them using a Java object.\nWhy do we need @ConfigurationProperties? What about the @Value annotation? The typical method of registering configuration properties to a Java object field in a Spring Boot application is the @Value annotation, but it is only acceptable for single independent configuration. If we want contextual settings for a specific task, as explained below, the @Value annotation is redundant and ineffective.\nservices: - name: HTTP_SERVICE type: REST enable: true setting: endpoint: http://test.com/test content-type: application/json Now let\u0026rsquo;s try to configure the above properties for Java class fields as\nclass AppSetting { @Value(\u0026#34;${services.name}\u0026#34;) serviceName; @Value(\u0026#34;${services.type}\u0026#34;) serviceType; @Value(\u0026#34;${services.enable}\u0026#34;) serviceEnable; @Value(\u0026#34;${services.setting.endpoint}\u0026#34;) serviceSettingEndpoint; @Value(\u0026#34;${services.setting.content-tpe}\u0026#34;) serviceSettingContentType; } You can see how difficult it is to map complicated properties using the @Value annotation, which is why Spring Boot created the new annotation @ConfigurationProperties to address the issue.\nApplication Properties For this tutorial, we have defined the following application properties in a YAML file.\napplication.yml app: settings: services: - name: HTTP_SERVICE type: REST enable: true - name: JMS_SERVICE type: MESSAGE enable: false file: name: archive path: /archive Now lets work on Java code to map above configurations\nJava Code ServiceSettingConfig public class ServiceSettingConfig { } To make it configurable with YAML services, we will use @ConfigurationProperties with a prefix of app.settings.\n@ConfigurationProperties(prefix = \u0026#34;app.settings\u0026#34;) public class ServiceSettingConfig { } Now we can map configurations to Java fields as\n@ConfigurationProperties(prefix = \u0026#34;app.settings\u0026#34;) public class ServiceSettingConfig { private List\u0026lt;?\u0026gt; services; } Here ? represents a Java object that represents the following YAML configurations.\nname: HTTP_SERVICE type: REST enable: true As a result, we must define a new Java class that represents these as fields. ServiceSetting.java public class ServiceSetting { private String name; private String type; private Boolean enable; public String getName() { return name; } public void setName(final String name) { this.name = name; } public String getType() { return type; } public void setType(final String type) { this.type = type; } public Boolean getEnable() { return enable; } public void setEnable(final Boolean enable) { this.enable = enable; } } Now we can complete our configurations as\nServiceSettingConfig.java @Configuration @ConfigurationProperties(prefix = \u0026#34;app.settings\u0026#34;) public class ServiceSettingConfig { private List\u0026lt;ServiceSetting\u0026gt; services; public List\u0026lt;ServiceSetting\u0026gt; getServices() { return services; } public void setServices(final List\u0026lt;ServiceSetting\u0026gt; services) { this.services = services; } } Pay attention to two things\n  first, the @Configuration annotation; in order to use this class within the application, you must load it as a configuration bean.\n  Second is the field name, private ListServiceSetting\u0026gt; services, which maps to app.settings.services of YAML, though the class name is different, ServiceSetting. It makes no difference what the class name is, but the field name must match the YAML configuration property.\n  Conclusion I hope this tutorial helps you understand the basic usage of @ConfigurationProperties. The source code related to this tutorial is present on my Github page.\n","permalink":"https://www.zainabed.com/tutorials/spring-boot-configuration-properties-tutorial/","summary":"Introduction This tutorial will show you how to use @ConfigurationProperties in a Spring Boot application. This annotation is designed to load properties from an application property file into an application context and configure them using a Java object.\nWhy do we need @ConfigurationProperties? What about the @Value annotation? The typical method of registering configuration properties to a Java object field in a Spring Boot application is the @Value annotation, but it is only acceptable for single independent configuration.","title":"How To Use @ConfigurationProperties In Spring Boot "},{"content":"Introduction This tutorial will walk you through the process of creating a basic unit test case for an Angular service. Angular services enable you to decompose complex business logic into small, reusable units that can then be injected into components or other services using dependency injection.\nThis tutorial is divided into two parts:\n One for creating a service by instantiating it sing new keyword. And another for injecting it using the Angular TestBed module.  Service The structure of the Token class is shown in the following snippet. token.ts export class Token { timestamp: number = 0; userId: number = 0; } The Token class contains the token\u0026rsquo;s expiration timestamp, user id, and token signature.\nThe next step is to validate this token object using an Angular service.\ntoke.service.ts import { Token } from \u0026#39;./token\u0026#39;; export class TokenService { isValidToken(token: Token): boolean { let currentTime = Date.now(); let timeDifference: number = token.timestamp - currentTime; if (timeDifference \u0026lt; 0) { return false; } else { return true; } } } To validate the token, the service will compute the difference between the current time and the moment it was created. If the current time exceeds the token time or expiry time, the token is considered invalid, and the method returns the appropriate boolean value.\nNow we can test the above method\u0026rsquo;s behaviour against two scenarios:\n One with an expired token, which should return a false value And one with a non-expired token, which should return a true value.  Unit Test token.service.spec.ts import { Token } from \u0026#39;./token\u0026#39;; import { TokenService } from \u0026#39;./token.service\u0026#39;; describe(\u0026#39;TokenSerrvice test cases\u0026#39;, () =\u0026gt; { var tokenService: TokenService; var tokenTime: number; beforeEach(() =\u0026gt; { tokenService = new TokenService(); }); it(\u0026#39;Should return false for expired token\u0026#39;, () =\u0026gt; { tokenTime = Date.now() - 50; let token: Token = { timestamp: tokenTime, userId: 1212 }; let result: boolean = tokenService.isValidToken(token); expect(result).toBeFalse(); }); it(\u0026#39;Should return true for valid token\u0026#39;, () =\u0026gt; { tokenTime = Date.now() + 5000; let token: Token = { timestamp: tokenTime, userId: 1212 }; let result: boolean = tokenService.isValidToken(token); expect(result).toBeTrue(); }); }); beforeEach will create a new TokenService instance. Another way to obtain an instance of the service is to use the TestBed module, as seen below\nTestBed Configuration beforeEach(() =\u0026gt; { TestBed.configureTestingModule({ providers: [TokenService] }) tokenService = TestBed.inject(TokenService); }) TestBed is an Angular-specific utility for unit testing; it allows us to auto-load services and any dependencies associated with them, and it provides a production-ready environment for unit testing.\nNow the question is, which of these should I choose? The answer is dependent on your working style, if you want to control service creation, the first option is preferable, if you prefer Angular to handle service instantiation, the second option is advisable.\nConclusion Angular services are lightweight and independent of UI components. Therefore, you can build the service and verify its behaviour using unit test cases without the need to bootstrap your Angular application and browser.\nYou can find source code on the Github page.\n","permalink":"https://www.zainabed.com/tutorials/how-to-write-angular-service-unit-test/","summary":"Introduction This tutorial will walk you through the process of creating a basic unit test case for an Angular service. Angular services enable you to decompose complex business logic into small, reusable units that can then be injected into components or other services using dependency injection.\nThis tutorial is divided into two parts:\n One for creating a service by instantiating it sing new keyword. And another for injecting it using the Angular TestBed module.","title":"How To Write Angular Service Unit Test"},{"content":"What is YAML to JSON converter tool Convert YAML to JSON for free, quickly, and conveniently in your browser.\nEnter your input below and click the Convert button. The result will be displayed below the Convert button.\n Enter the YAML Clear  \n Convert  JSON    What is YAML YAML is a human-readable data-serialization language. It is frequently used in configuration files as well as programmes that store or transport data.\nYAML is typically used to build application configuration and system specifications. It\u0026rsquo;s a popular configuration language in well-known frameworks like Spring Boot, Docker and Kubernetes and many more.\nWhat is JSON JSON, which stands for JavaScript Object Notation, is a well known text formatted structured data.\nIn general, JSON can represent\n No SQL database record Application configuration Application configuration No SQL database record  As you can see, JSON is utilised in a variety of scenarios, implying that it has a standard data structure.\nJSON is a language-independent data format that is based on a subset of the JavaScript scripting language. It is often used with JavaScript.\nThe JSON website lists JSON libraries by language.\n  #outputBox { width: 100%; }   ","permalink":"https://www.zainabed.com/tools/yaml-to-json/","summary":"What is YAML to JSON converter tool Convert YAML to JSON for free, quickly, and conveniently in your browser.\nEnter your input below and click the Convert button. The result will be displayed below the Convert button.\n Enter the YAML Clear  \n Convert  JSON    What is YAML YAML is a human-readable data-serialization language. It is frequently used in configuration files as well as programmes that store or transport data.","title":"Online YAML to JSON Converter"},{"content":"Introduction There are several methods for testing Rest controllers in the Spring Boot framework, and this post will demonstrate one of the quickest.\nTools  Spring Boot: 2.7.6\nJava : 11\n Rest Controller Let\u0026rsquo;s create a simple REST API controller with one service to fetch the data from the database.\nUserController.java @RestController public class UserController { private final UserService userService; public UserController(final UserService userService) { this.userService = userService; } @PostMapping(path = \u0026#34;/user\u0026#34;, consumes = MediaType.APPLICATION_JSON_VALUE, produces = MediaType.APPLICATION_JSON_VALUE) public ResponseEntity\u0026lt;User\u0026gt; createUser(@RequestBody User user) { final User savedUser = userService.save(user); return ResponseEntity.ok(savedUser); } } The code above is self-explanatory, but we\u0026rsquo;ll go over a few topics.\n  The most crucial sentence in the preceding snippet is @WebMvcTest(UserController.class), which lightens the test suite by removing the Spring Boot application context.\n  The createUser method takes a User object request and passes it to the serice, which saves it in the database and returns the saved User object as a response.\n  Pay close attention to the UserServicve interface, we will not define any implementation of it here; Instead, we will use unit test mocking to inject a dummy class that will function as a service to store User instances.\n  UserService.java public interface UserService { User save(User user); } Unit Test Only UserController will be loaded into the web context, and the Spring Boot application context will be left out of the test suite. The test suite is lighter and faster when the complete application context is removed.\nWe also need to mock UserService because Spring context isn\u0026rsquo;t available to autowire it. This adds another benefit to our test suite because we don\u0026rsquo;t have to worry about implementing business logic while developing the REST controller.\nHere, we will simply test the REST controller\u0026rsquo;s input and output, ensuring that all essential business service calls are triggered and provide an appropriate response.\nUserControllerTest.java @WebMvcTest(UserController.class) class UserControllerTest { @MockBean private UserService userService; @Autowired MockMvc mockMvc; private User userRequest; private User userResponse; @BeforeEach void setUp() { final String username = \u0026#34;test name\u0026#34;; final String userAddress = \u0026#34;test address\u0026#34;; userRequest = new User(username, userAddress); userResponse = new User(username, userAddress); when(userService.save(userRequest)).thenReturn(userResponse); } @Test void should_save_requested_user() throws Exception { final String requestBody = new ObjectMapper().writeValueAsString(userRequest); mockMvc.perform(post(\u0026#34;/user\u0026#34;).contentType(MediaType.APPLICATION_JSON) .content(requestBody)) .andExpect(status().isOk()); } } Within the @BeforeEach function, we imitate the UserService behaviour of saving the User record into the database.\nWe assert the REST call status after sending the required User record to the controller and returning the stored User object as a response.\nRun the test case using the editor or the command.\nmvn test It will result in something like\n022-12-21 12:34:49.968 INFO 53510 --- [ main] c.z.tutorials.user.UserControllerTest : Started UserControllerTest in 3.531 seconds (JVM running for 5.266) [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.818 s - in com.zainabed.tutorials.user.UserControllerTest [INFO] [INFO] Results: [INFO] [INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0 [INFO] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS Conclusion Loading only the REST Controller into the test suite context is a great feature of the Spring Boot application, and it makes writing and testing the REST Controller faster.\nBut don\u0026rsquo;t make this your default method of writing test cases; remember, this is a unit test for the REST Controller, not an integration test. To make an application behave properly with rest of services, such as business logic, a database, or a third-party library or service, the entire application context must be loaded and the REST controller tested. You can find the source code used in this tutorial on the Github page.\n","permalink":"https://www.zainabed.com/tutorials/spring-boot-controller-test/","summary":"Introduction There are several methods for testing Rest controllers in the Spring Boot framework, and this post will demonstrate one of the quickest.\nTools  Spring Boot: 2.7.6\nJava : 11\n Rest Controller Let\u0026rsquo;s create a simple REST API controller with one service to fetch the data from the database.\nUserController.java @RestController public class UserController { private final UserService userService; public UserController(final UserService userService) { this.userService = userService; } @PostMapping(path = \u0026#34;/user\u0026#34;, consumes = MediaType.","title":"How To Make Spring Boot Controller Unit Test Faster"},{"content":" Enter the input Clear  \n Hash  SHA-256 \n What is SHA-256? SHA-256 is a cryptographic hash function that accepts a random-sized input and returns a 256-bit fixed-size hash as an output.\nBecause of their one-way output, such hashes are extremely powerful. Simply said, you can generate a hash output from any given input, but you cannot reconstruct the original data from the same hash output.\n ","permalink":"https://www.zainabed.com/tools/sha256/","summary":"Enter the input Clear  \n Hash  SHA-256 \n What is SHA-256? SHA-256 is a cryptographic hash function that accepts a random-sized input and returns a 256-bit fixed-size hash as an output.\nBecause of their one-way output, such hashes are extremely powerful. Simply said, you can generate a hash output from any given input, but you cannot reconstruct the original data from the same hash output.","title":"SHA-256 Online Tool"},{"content":" Encode Decode   Enter the text for  Clear  \n Base64   Base64  \n Base64 Encoder / Decoder Online Base64 Decode is a simple utility for decoding or encoding base64 data to plain text.\nWhat exactly is Base64? Base64 is a family of binary-to-text encoding techniques that convert binary data in an ASCII string format into a radix-64 representation.\nBase64 is commonly used to encode binary data in email messages and web pages. It is also used to send binary files over channels that are not 8-bit clean or where byte order is not an issue.\nPlease see the Base64 Wikipedia page for further information.\n ","permalink":"https://www.zainabed.com/tools/base64/","summary":"Encode Decode   Enter the text for  Clear  \n Base64   Base64  \n Base64 Encoder / Decoder Online Base64 Decode is a simple utility for decoding or encoding base64 data to plain text.\nWhat exactly is Base64? Base64 is a family of binary-to-text encoding techniques that convert binary data in an ASCII string format into a radix-64 representation.\nBase64 is commonly used to encode binary data in email messages and web pages.","title":"Base64 Online Tool"},{"content":"Introduction How often do you create a Maven project from your preferred editor? The response would be frequently or always.\nBut have you ever thought about what Maven command your editor used to create the project? Yes, maven projects are built solely with the maven command, exactly as \u0026ldquo;mvn clean install\u0026rdquo; is used to create a project\u0026rsquo;s jar file.\nThis tutorial will teach you about such a command.\nMaven Command Open your terminal and navigate to the directory in which you want to create a new Maven project. After that, run the following command.\nmvn archetype:generate \\  -DgroupId=com.zainabed.project \\  -DartifactId=sample-maven-app \\  -DarchetypeArtifactId=maven-archetype-quickstart \\  -DarchetypeVersion=1.4 \\  -DinteractiveMode=false  Note: You must have Maven installed on your workstation before running this command; otherwise, it will fail.  The above command will create a new Maven project with an application class and its test file. The structure of the generated project will follow.\nDirectory Structure sample-maven-app ├── pom.xml └── src ├── main │ └── java │ └── com │ └── zainabed │ └── project │ └── App.java └── test └── java └── com └── zainabed └── project └── AppTest.java Structure Now let\u0026rsquo;s have a look at each of the parameters of the above command.\n   Parameter Description     archetype Archetype is a Maven project template toolkit. Use the mvn archetype: generate goal to create a project using the selected template.   groupId The groupId identifies your project uniquely across all projects.    artifactId It is the name of the jar without a version.   archetypeVersion It is the jar version number, the typical version could be numbers and dots (1.0, 1.1, 1.0.1, \u0026hellip;).   archetypeArtifactId It is the archetype template name, it helps Maven create the initial structure of the project.   interactiveMode It allows Maven to interact with the user for input, a false value will disable it by picking up deficient values.    pom.xml The following XML represents the Maven project structure.\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.zainabed.project\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sample-maven-app\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;sample-maven-app\u0026lt;/name\u0026gt; \u0026lt;!-- FIXME change it to the project\u0026#39;s website --\u0026gt; \u0026lt;url\u0026gt;http://www.example.com\u0026lt;/url\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;maven.compiler.source\u0026gt;1.7\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;1.7\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.11\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/project\u0026gt; Start Application Run the following command to verify the project structure and create a runable jar file.\nmvn clean install Now, execute the JAR file using the following command.\njava -cp target/sample-maven-app-1.0-SNAPSHOT.jar com.zainabed.project.App Hello World!  Note: Here com.zainabed.project.App is appended to the above command to help it identify the application starter class.\n Archetype List This tutorial illustrated the use of the \u0026ldquo;maven-archetype-quickstart\u0026rdquo; archetype, however Maven is not restricted to this choice, there are several others listed below.\n   Archetype ArtifactIds Description     maven-archetype-archetype An archetype to generate a sample archetype.   maven-archetype-j2ee-simple An archetype to generate a simplifed sample J2EE application.   maven-archetype-plugin An archetype to generate a sample Maven plugin.   maven-archetype-plugin-site An archetype to generate a sample Maven plugin site.   maven-archetype-portlet An archetype to generate a sample JSR-268 Portlet.   maven-archetype-quickstart An archetype to generate a sample Maven project.   maven-archetype-simple An archetype to generate a simple Maven project.   maven-archetype-site An archetype to generate a sample Maven site which demonstrates some of the supported document types like APT, Markdown, XDoc, and FML and demonstrates how to i18n your site.   maven-archetype-site-simple An archetype to generate a sample Maven site.   maven-archetype-site-skin An archetype to generate a sample Maven Site Skin.   maven-archetype-webapp An archetype to generate a sample Maven Webapp project.    Conclusion I expect this tutorial has helped you better grasp the Maven command for creating a project. This tutorial\u0026rsquo;s source code is accessible on Github.\n","permalink":"https://www.zainabed.com/tutorials/maven-create-a-project-command-line/","summary":"Introduction How often do you create a Maven project from your preferred editor? The response would be frequently or always.\nBut have you ever thought about what Maven command your editor used to create the project? Yes, maven projects are built solely with the maven command, exactly as \u0026ldquo;mvn clean install\u0026rdquo; is used to create a project\u0026rsquo;s jar file.\nThis tutorial will teach you about such a command.\nMaven Command Open your terminal and navigate to the directory in which you want to create a new Maven project.","title":"Create Maven Project Through Command Line"},{"content":"Introduction Spring Boot applications can save informative messages or application errors to a file. This functionality allows you to monitor the application\u0026rsquo;s health and take necessary action when problems arise.\nLogging all of this information to a single file, on the other hand, will cause the file to expand in size, which would be a nightmare if the file size rose to MB or GB and you wanted to trace a specific exception throughout the whole log file.\nTherefore, each logging library provides a feature to distribute application logs into an n-number of files. And in this tutorial, we\u0026rsquo;ll look into a Log4j2 functionality like that.\nThis feauture is names as RollingFile Appender in Log4j2.\nRollingFile Configuration Log4j2\u0026rsquo;s RollingFile appender setting allows you to separate logs based on date and time, size, or both rules.\nTo begin with the initial setup of log4j, please see the Two Steps To Add Log4j2 To Spring Boot Application tutorial.\nNow, to apply the RollingFile configuration, modify the log4j2.xml file.\nsrc/main/resources/log4j2-rolling-file.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Configuration status=\u0026#34;ERROR\u0026#34;\u0026gt; \u0026lt;Properties\u0026gt; \u0026lt;Property name=\u0026#34;LOG_PATTERN\u0026#34;\u0026gt;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026#34;\u0026lt;/Property\u0026gt; \u0026lt;Property name=\u0026#34;LOG_DIR\u0026#34;\u0026gt;logs\u0026lt;/Property\u0026gt; \u0026lt;Property name=\u0026#34;LOG_FILE_NAME\u0026#34;\u0026gt;logging\u0026lt;/Property\u0026gt; \u0026lt;/Properties\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;Console name=\u0026#34;Console\u0026#34; target=\u0026#34;SYSTEM_OUT\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026#34;/\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;RollingFile name=\u0026#34;dailyFileLog\u0026#34; fileName=\u0026#34;${LOG_DIR}/${LOG_FILE_NAME}.log\u0026#34; filePattern=\u0026#34;${LOG_DIR}/${LOG_FILE_NAME}-%d{dd-MM-yyyy}.log\u0026#34;\u0026gt; \u0026lt;Policies\u0026gt; \u0026lt;TimeBasedTriggeringPolicy/\u0026gt; \u0026lt;/Policies\u0026gt; \u0026lt;/RollingFile\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;Logger name=\u0026#34;com.zainabed\u0026#34; level=\u0026#34;INFO\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;dailyFileLog\u0026#34;/\u0026gt; \u0026lt;/Logger\u0026gt; \u0026lt;Root level=\u0026#34;INFO\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; The \u0026ldquo;RollingFile\u0026rdquo; setup will be in charge of breaking logs into different log files. It has the following characteristics:\n name: the name of the RollingFile configuration to be used in the Logger tag. fileName: path to the system log file. filePattern: pattern for creating rolling log files.  The policy for splitting files is defined in the preceding code snippet. Here, the policy indicates that logs should be distributed based on a time-based policy.\n\u0026lt;Policies\u0026gt; \u0026lt;TimeBasedTriggeringPolicy/\u0026gt; \u0026lt;/Policies\u0026gt;  Note: Log4j2 creates files based on filePattern, and you can find previous days' logs according to those patterns.\n Result You can put everything together and run application.\n$ ls logs/ logging.log And if you run the same application the next day, old logs are archived and saved in a file that conforms to the pattern specified in the RollingFile setting.\n$ ls logs/ logging-08-11-2022.log logging.log logging-08-11-2022.log contains logs of 8/11/2022 and logging.log will contain current days log.\nYAML configuration The same configurations can be established using an application. yml file as,\nsrc/main/resources/log4j2-rolling-file.yml Configutation: status: warn Properties: Property: - name: LOG_DIR value: logs - name: LOG_FILE_NAME value: logging Appenders: Console: name: CONSOLE target: SYSTEM_OUT PatternLayout: Pattern: \u0026#34;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026#34; RollingFile: - name: APPLICATION fileName: \u0026#34;${LOG_DIR}/${LOG_FILE_NAME}.log\u0026#34; filePattern: \u0026#34;${LOG_DIR}/${LOG_FILE_NAME}-%d{dd-MM-yyyy}.log\u0026#34; PatternLayout: Pattern: \u0026#34;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026#34; policies: TimeBasedTriggeringPolicy: interval: 1 modulate: true Loggers: Root: level: info AppenderRef: - ref: CONSOLE - ref: APPLICATION Logger: - name: com.zainabed additivity: false level: info AppenderRef: - ref: CONSOLE - ref: APPLICATION - name: com.myco.myapp.Bar additivity: false level: debug AppenderRef: - ref: CONSOLE - ref: APPLICATION Conclusion Congratulation! You\u0026rsquo;ve learned about Log4j2\u0026rsquo;s RollingFile appender, and as always, the source code for this tutorial can be found on Github.\n","permalink":"https://www.zainabed.com/tutorials/spring-log4j2-rolling-file/","summary":"Introduction Spring Boot applications can save informative messages or application errors to a file. This functionality allows you to monitor the application\u0026rsquo;s health and take necessary action when problems arise.\nLogging all of this information to a single file, on the other hand, will cause the file to expand in size, which would be a nightmare if the file size rose to MB or GB and you wanted to trace a specific exception throughout the whole log file.","title":"Easy Steps To Create Log4j2 Rolling File For Spring Boot"},{"content":"Introduction Log4j2 is a comprehensive and modern framework for logging messages in applications.\nAnd Spring Boot, which is widely used in industry, provides excellent support for Log4j2.\nIn this tutorial, we will look at how to configure it using an XML and YAML file.\nSetup Download the Spring Boot application from Spring Boot Starter and extract the zip file.\nPOM Configuration Add log4j2 as a dependency to the pom.xml file. pom.xml \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-log4j2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;  Note: Because Spring Boot Web includes Logback as a default logging dependency, we must remove it from the classpath to avoid a collision with Log4j2.\n Remove default Logback logging by updating pom.xml as follows\npom.xml \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; Gradle Configuration For the Gradle project, add the following dependencies to enable log4j2.\ndependencies { --- implementation \u0026#39;org.springframework.boot:spring-boot-starter-log4j2:2.6.13\u0026#39; --- } XML Log4j2 File To enable console logging, create a log4j2.xml file in the application resources folder and add the following configuration.\nsrc/main/resources/log4j2.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Configuration status=\u0026#34;ERROR\u0026#34;\u0026gt; \u0026lt;Properties\u0026gt; \u0026lt;Property name=\u0026#34;LOG_PATTERN\u0026#34;\u0026gt;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026#34;\u0026lt;/Property\u0026gt; \u0026lt;/Properties\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;Console name=\u0026#34;Console\u0026#34; target=\u0026#34;SYSTEM_OUT\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;${LOG_PATTERN}\u0026#34;/\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;Root level=\u0026#34;INFO\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; This adequate configuration will log INFO messages into Console.\nNow, add some INFO logs to application as,\nDemoLog4j2Application.java import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class DemoLog4j2Application { private static final Logger LOGGER = LogManager.getLogger(DemoLog4j2Application.class); public static void main(String[] args) { LOGGER.info(\u0026#34;Application starts\u0026#34;); SpringApplication.run(DemoLog4j2Application.class, args); LOGGER.info(\u0026#34;Application ends\u0026#34;); } } When you run the application, the log messages will display in the configure logs pattern.\nTerminal 04:37:04.009 [main] INFO com.zainabed.tutorial.demolog4j2.DemoLog4j2Application - Application starts ..... ..... ..... 04:37:07.430 [main] INFO com.zainabed.tutorial.demolog4j2.DemoLog4j2Application - Started DemoLog4j2Application in 3.278 seconds (JVM running for 4.868) 04:37:07.434 [main] INFO com.zainabed.tutorial.demolog4j2.DemoLog4j2Application - Application ends YAML Log4j2 File A YAML file can also be used to configure log4j2. We can achieve this goal with minimal effort by using following configuration.\nlog4j2.yml Configutation: status: warn Properties: Property: - name: Pattern value: \u0026#39;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026#39; Appenders: Console: name: CONSOLE target: SYSTEM_OUT PatternLayout: Pattern: \u0026#34;${Pattern}\u0026#34; Loggers: Root: level: info AppenderRef: - ref: CONSOLE - ref: APPLICATION Keep in mind that the log4j2.xml file is Spring Boot\u0026rsquo;s default logging configuration, just specifying a YAML file will not help you select it.\nTo force the application to use YAML configuration, we must make two changes.\nFirst add following dependency\npom.xml \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.fasterxml.jackson.dataformat\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-dataformat-yaml\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.0-rc4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; It will help the application translate the YAML configuration.\nAnd for Gradle project update following file\nbuild.gradle dependencies { --- --- implementation \u0026#39;com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:2.6.0-rc4\u0026#39; } The second step is to include a reference to YAML in the application property file.\napplication.properties logging.config=src/main/resources/log4j2.yml Conclusion This post taught you how to enable Lo4j2 logging in your Spring Boot application using various configuration approaches.\nYou can find the source code for this tutorial at the Github project.\n","permalink":"https://www.zainabed.com/tutorials/spring-boot-log4j2-setup/","summary":"Introduction Log4j2 is a comprehensive and modern framework for logging messages in applications.\nAnd Spring Boot, which is widely used in industry, provides excellent support for Log4j2.\nIn this tutorial, we will look at how to configure it using an XML and YAML file.\nSetup Download the Spring Boot application from Spring Boot Starter and extract the zip file.\nPOM Configuration Add log4j2 as a dependency to the pom.xml file. pom.","title":"Two Steps To Add Log4j2 To Spring Boot Application"},{"content":"Introduction This tutorial is a short introduction to Spring Cloud Gateway.\nBy following the quick and easy steps provided below, you will be able to start the REST API gateway project.\nPrerequisite  Java Maven Spring Boot  Download the Spring Boot project from Spring Initializr and select Gateway  as dependency.\nNow generate and download the project and use your favourite editor to import it.\nGateway Configuration You can use a YAML file or Java code to configure routes. Either way, you will see both of these approaches in this tutorial.\nYAML configuration Edit application.yml and add following snippet\nspring: cloud: gateway: routes: - id: user-service uri: http://localhost:3000  Note : The Spring Boot Gateway is a bridge between clients and your application server. Therefore, clients will interact with Gateway instead of your application server. In this tutorial, your server is running at http://localhost:3000.\n For this tutorial, we are using mock-server which is running on port 3000. You can run the Spring Boot application on its default 8080 port.\nCheck out How To Use json-server To Build Mock REST API Server tutorial.\nNow that Gateway and the mock-server are up and running, we can Curl to test the end-to-end flow.\nRun the following curl command to verify the mock-server is functioning well.\ncurl --location --request GET \u0026#39;http://localhost:3000/user\u0026#39; the result should be something like this,\n[ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Jonathan\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;USA\u0026#34; } ] Now we will execute the same Curl command, but instead of port 3000 we will use 8080 (Gateway application).\nAnd we expect the result should be the same as Gateway is the bridge for the backend server (the mock-server in this tutorial).\ncurl --location --request GET \u0026#39;http://localhost:8080/user\u0026#39; and response must be\n[ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Jonathan\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;USA\u0026#34; } ] Bean Configuration Create a bean to configure the routes for the mock user service.\nRouteConfiguration.java @Configuration public class RouteConfiguration { @Bean public RouteLocator userServiceRoutes(RouteLocatorBuilder builder) { return builder.routes() .route(config -\u0026gt; config.path(\u0026#34;/user\u0026#34;) .uri(\u0026#34;http://localhost:3000\u0026#34;) ).build(); } } Here, userServiceRoutes method creates RouteLocator bean, and this bean will configure the routes inside Spring Boot Gateway.\nUsing a lambda expression, we setup the uri as http://localhost:3000, the endpoint to mock-server and the path as /user the user service path of mock-server.\n Note: To work with Spring Beans, we first need to turn off the application.yml configurations by commenting on them.\n Now run the application and test the end-to-end flow.\ncurl --location --request GET \u0026#39;http://localhost:8080/user\u0026#39; and response should be\n[ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Jonathan\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;USA\u0026#34; } ] Conclusion Congratulations! You have just finished developing your first Spring Cloud Gateway application. As is customary, you can obtain the source code for this tutorial on Github.\n","permalink":"https://www.zainabed.com/tutorials/spring-boot-cloud-gateway-introduction/","summary":"Introduction This tutorial is a short introduction to Spring Cloud Gateway.\nBy following the quick and easy steps provided below, you will be able to start the REST API gateway project.\nPrerequisite  Java Maven Spring Boot  Download the Spring Boot project from Spring Initializr and select Gateway  as dependency.\nNow generate and download the project and use your favourite editor to import it.\nGateway Configuration You can use a YAML file or Java code to configure routes.","title":"First Step Toward Spring Boot Cloud Gateway "},{"content":"Introduction A mock REST API server will often expedite your integration testing, and this tutorial will give you insight into one such server.\nThis tutorial will walk through each step of setting up and using a fake server.\n Software used in this tutorial  NPM : 8.3.1 Node: 16.14.0 Json-Server: 0.17.0   Setup The first step is to make sure you have node and npm installed on your workstation, then follow the next commands.\njson-server installation Run the following command to install the latest version of json-server\nnpm install -g json-server You can also install a specific version as\nnpm install -g json-server@0.17.0 Resource Defination json-server requires a JSON file to configure the HTTP routes. For example, if we want to create a REST API for a user module, we need to provide the following kind of JSON structure.\nresources.json { \u0026#34;user\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Jonathan\u0026#34; , \u0026#34;address\u0026#34; : \u0026#34;USA\u0026#34; } ] } The JSON mock server will convert this data structure to REST API routes as\n GET http://localhost:{port}/user GET http://localhost:{port}/user/{id} POST http://localhost:{port}/user PUT http://localhost:{port}/user/{id} DELETE http://localhost:{port}/user/{id}  Start the server Run the following command to start the mock server.\njson-server resources.json And the server will start by emitting something like the following output.\n\\{^_^}/ hi! Loading resources.json Done Resources http://localhost:3000/user Home http://localhost:3000 Type s + enter at any time to create a snapshot of the database Testing We can use Curl commands to verify the mock server\u0026rsquo;s REST API endpoints and their behaviour with different HTTP method calls.\nGET Request curl --location --request GET \u0026#39;http://localhost:3000/user/1\u0026#39; Response { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Jonathan\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;USA\u0026#34; }  POST Request curl --location --request POST \u0026#39;http://localhost:3000/user\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --data-raw \u0026#39; { \u0026#34;name\u0026#34;: \u0026#34;Stefan\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;Germany\u0026#34; }\u0026#39; Response { \u0026#34;name\u0026#34;: \u0026#34;Stefan\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;Germany\u0026#34;, \u0026#34;id\u0026#34;: 2 }  GET all users curl --location --request GET \u0026#39;http://localhost:3000/user\u0026#39; Response [ { \u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;Jonathan\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;USA\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Stefan\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;Germany\u0026#34;, \u0026#34;id\u0026#34;: 2 } ]  Delete Request curl --location --request DELETE \u0026#39;http://localhost:3000/user/1\u0026#39; Conclusion In an agile world, we need smart tools that keep the feedback loop faster, increase productivity, and decrease dependency, and JSON-Server is one of those tools.\nYou can find the source code related to this tutorial on the Github page.\n","permalink":"https://www.zainabed.com/tutorials/create-mock-server-using-json-server/","summary":"Introduction A mock REST API server will often expedite your integration testing, and this tutorial will give you insight into one such server.\nThis tutorial will walk through each step of setting up and using a fake server.\n Software used in this tutorial  NPM : 8.3.1 Node: 16.14.0 Json-Server: 0.17.0   Setup The first step is to make sure you have node and npm installed on your workstation, then follow the next commands.","title":"How To Use json-server To Build Mock REST API Server"},{"content":"Introduction This quick tutorial will show you how to use Spring Boot RestTemplate to upload a file to a server.\nThe prerequisites for this tutorial are the following\n the server that accepts requests for multipart file uploads A RestTemplate instance Of course, a text file to upload.   What You Need This tutorial uses following softwares  Java: 1.8 Spring Boot: 2.7.4 Maven: 3.6.3  How to upload a file First we create an instance of RestTemplate as\nfinal RestTemplate restTemplate = new RestTemplate(); Next, by including the required headers in the requests, we should inform RestTemplate to accept multipart requests.\nfinal HttpHeaders httpHeaders = new HttpHeaders(); httpHeaders.setContentType(MediaType.MULTIPART_FORM_DATA);  Note: HTTP multipart requests are used to transfer text or binary files to the server.\n Create temporary text file To upload a file to the server, we need to create a file, which is what we will do in following snippet.\nprivate File getFile() { try { Path file = Files.createTempFile(\u0026#34;test\u0026#34;, \u0026#34;.txt\u0026#34;); log.info(\u0026#34;file is created with name {}\u0026#34;, file.getFileName()); return file.toFile(); } catch (IOException e) { e.printStackTrace(); } return null; } To upload this file, let\u0026rsquo;s make a FileSystemResource out of newly created file and connect it to a HttpEntity.\nfinal File uploadFile = getFile(); final FileSystemResource fileSystemResource = new FileSystemResource(uploadFile); final MultiValueMap\u0026lt;String, Object\u0026gt; fileUploadMap = new LinkedMultiValueMap\u0026lt;\u0026gt;(); fileUploadMap.set(\u0026#34;file\u0026#34;, fileSystemResource); Now, create a HttpEntity as\nHttpEntity\u0026lt;MultiValueMap\u0026lt;String, Object\u0026gt;\u0026gt; httpEntity = new HttpEntity\u0026lt;\u0026gt;(fileUploadMap, httpHeaders); Since everything is in place, all that remains is to make the REST call to upload the file to the server.\nTo do so, add the following snippet\nResponseEntity\u0026lt;String\u0026gt; responseEntity = restTemplate.postForEntity(\u0026#34;http://localhost:8090/file-upload\u0026#34;, httpEntity, String.class); Complete Source file Here is the complete service file code.\nFileUploadService.java @Service @Log4j2 public class FileUploadService { public static final String FILE_PARAMETER_NAME = \u0026#34;file\u0026#34;; public static final String FILE_UPLOAD_URL = \u0026#34;http://localhost:8090/file-upload\u0026#34;; private final RestTemplate restTemplate; public FileUploadService() { restTemplate = new RestTemplate(); } @Scheduled(fixedDelay = 1000) public boolean uploadMultipartFile() { final HttpHeaders httpHeaders = new HttpHeaders(); httpHeaders.setContentType(MediaType.MULTIPART_FORM_DATA); final File uploadFile = getFile(); final FileSystemResource fileSystemResource = new FileSystemResource(uploadFile); final MultiValueMap\u0026lt;String, Object\u0026gt; fileUploadMap = new LinkedMultiValueMap\u0026lt;\u0026gt;(); fileUploadMap.set(FILE_PARAMETER_NAME, fileSystemResource); HttpEntity\u0026lt;MultiValueMap\u0026lt;String, Object\u0026gt;\u0026gt; httpEntity = new HttpEntity\u0026lt;\u0026gt;(fileUploadMap, httpHeaders); ResponseEntity\u0026lt;String\u0026gt; responseEntity = restTemplate.postForEntity(FILE_UPLOAD_URL, httpEntity, String.class); return responseEntity.getStatusCode().equals(HttpStatus.OK); } private File getFile() { try { Path file = Files.createTempFile(\u0026#34;test\u0026#34;, \u0026#34;.txt\u0026#34;); log.info(\u0026#34;file is created with name {}\u0026#34;, file.getFileName()); return file.toFile(); } catch (IOException e) { e.printStackTrace(); } return null; } } You need a REST application to save the file in order to test this file upload service. The server-client code is ready on the Gituhb project, however this tutorial only showcases the client-side service.\nPlease check the Github project link at the tutorial\u0026rsquo;s conclusion.\nYou will receive the subsequent type of response after starting the service and establishing a connection with the server.\n2022-10-19 08:58:03.090 INFO: file is created with name test181876724622311090.txt 2022-10-19 08:58:03.105 INFO: Saved file with name test181876724622311090.txt Conclusion Congratulations, you\u0026rsquo;ve just finished using RestTemplate to upload a file. As usual, a Github project will contain the complete source code.\n","permalink":"https://www.zainabed.com/tutorials/upload-file-spring-resttemplate/","summary":"Introduction This quick tutorial will show you how to use Spring Boot RestTemplate to upload a file to a server.\nThe prerequisites for this tutorial are the following\n the server that accepts requests for multipart file uploads A RestTemplate instance Of course, a text file to upload.   What You Need This tutorial uses following softwares  Java: 1.8 Spring Boot: 2.7.4 Maven: 3.6.3  How to upload a file First we create an instance of RestTemplate as","title":"Spring Boot File Upload With RestTemplate"},{"content":"Introduction This blog post is designed to serve as a comprehensive guide for developers looking to apply mutation testing into their Angular application.\nIf you are that developer, you will be able to carry out mutation testing with ease by following the working configurations and examples provided below.\nIf you just happened onto this tutorial, you will gain a decent understanding of mutation testing. Please see here for a definition of the mutation test.\n  Note: For Angular, it is Stryker software to provide mutation testing capabilities.\n Configuration Install The first step is to install stryker-cli to initiate the Stryker project inside the Angular application.\nRun the following command to install Stryker-cli.\nnpm install --global stryker-cli Initialize Stryker project Run the following command to configure the Angular project with the Stryker mutation testing framework. To do so, please move into your application’s home directory.\nstryker init This will create the following file in the Angular application root folder.\nstriker.conf.json { \u0026#34;$schema\u0026#34;: \u0026#34;./node_modules/@stryker-mutator/core/schema/stryker-schema.json\u0026#34;, \u0026#34;_comment\u0026#34;: \u0026#34;This config was generated using \u0026#39;stryker init\u0026#39;. Please see the guide for more information: https://stryker-mutator.io/docs/stryker-js/guides/angular\u0026#34;, \u0026#34;mutate\u0026#34;: [ \u0026#34;src/**/*.ts\u0026#34;, \u0026#34;!src/**/*.spec.ts\u0026#34;, \u0026#34;!src/test.ts\u0026#34;, \u0026#34;!src/environments/*.ts\u0026#34; ], \u0026#34;testRunner\u0026#34;: \u0026#34;karma\u0026#34;, \u0026#34;karma\u0026#34;: { \u0026#34;configFile\u0026#34;: \u0026#34;karma.conf.js\u0026#34;, \u0026#34;projectType\u0026#34;: \u0026#34;angular-cli\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;browsers\u0026#34;: [ \u0026#34;ChromeHeadless\u0026#34; ] } }, \u0026#34;reporters\u0026#34;: [ \u0026#34;progress\u0026#34;, \u0026#34;clear-text\u0026#34;, \u0026#34;html\u0026#34; ], \u0026#34;concurrency\u0026#34;: 2, \u0026#34;concurrency_comment\u0026#34;: \u0026#34;Recommended to use about half of your available cores when running stryker with angular\u0026#34;, \u0026#34;coverageAnalysis\u0026#34;: \u0026#34;perTest\u0026#34; } Example Let\u0026rsquo;s have a look at a very simple unit test example.\nmutation.example.ts export function validateName(name: string): boolean { if (name == null || name.length \u0026lt; 4) { return false; } return true; } and 100% code coverage unit test for the above method is\nmutation.example.spec.ts import { validateName } from \u0026#34;./mutation.example\u0026#34;; describe(\u0026#34;Mutation test example.\u0026#34;, () =\u0026gt; { it(\u0026#34;Should return false for short name.\u0026#34;, () =\u0026gt; { let name = \u0026#34;abc\u0026#34;; expect(validateName(name)).toBeFalse(); }); it(\u0026#34;Should return true for correct name.\u0026#34;, () =\u0026gt; { let name = \u0026#34;Benjamin\u0026#34;; expect(validateName(name)).toBeTrue(); }); }); Code coverage will be\nTOTAL: 8 SUCCESS =============================== Coverage summary =============================== Statements : 100% ( 11/11 ) Branches : 100% ( 3/3 ) Functions : 100% ( 3/3 ) Lines : 100% ( 9/9 ) ================================================================================ Everything appears to be correct to an impulsive developer, but when we run a mutation test against it, we discover a hidden flaw. The mutation test reveals the other side of the story. mutation test report Red dots indicate the surviving mutations.\nHow it works Let\u0026rsquo;s see how mutation tests work.\nexport function validateName(name: string): boolean { - if (name == null || name.length \u0026lt; 4) { + if (false || name.length \u0026lt; 4) { return false; } return true; } So it replaces the name == null condition statement with a false statement and test cases run against this modified code. If the test passes, then it states that a mutation exists. Our job is to remove that mutation by adding a unit test case that handles such a scenario.\nIf we study the unit test cases and source code, we can see that there is no use of name == null, hence we must write a test case to pass an empty string and test it.\nUpdate Unit Test Cases The following is a unit test case to tackle the empty name condition check.\nit(\u0026#34;Should return for empty name\u0026#34;, ()=\u0026gt;{ let name = null; expect(validateName(name)).toBeFalse(); }); Next, Run following command\nstryker run And now the report will be like\nReport shows name == null mutation is removed.\nWhat is Mutation Testing Mutation testing is specialised software that improves unit testing in any programming language. Though it does not improve code coverage, it does identify the types of edge cases that we generally overlook.\nHow does it work? Well, in a nutshell, it changes the application code at run time before unit tests are executed and those test cases are run against the modified code.\nWhat does it change in code? it changes many things for example\nIf you have a condition statement like a \u0026gt; b then it changes it to a \u0026lt; b.\nNow your unit tests should handle such scenarios. If the test case fails, then it implies that the test case has eliminated the mutation from the code. If it doesn\u0026rsquo;t, then there is a need for improvement in test cases.\nStryker Mutation Framework As mentioned earlier, every language has specialised software for mutation testing. For Angular, it is Stryker software. It is an open source project and it supports more than 30 mutations. It also provides a very convenient report, which will help to improve test cases. For more information, go to its official website. Conclusion Mutation testing can also be supported by a sophisticated framework such as Angular. Though it reduces productivity since mutation test execution is slow, but it improves application sustainability, which we need in the long term.\n This blog post uses following softwares  Angular: 13.2.7 Node: 16.14.0 Typescript: 4.5.5 Stryker: 6.1.2   Source Code You can find source code used in this tutorial on Github page.\n","permalink":"https://www.zainabed.com/2022/08/how-angular-supports-mutation-testing-with-example.html/","summary":"Introduction This blog post is designed to serve as a comprehensive guide for developers looking to apply mutation testing into their Angular application.\nIf you are that developer, you will be able to carry out mutation testing with ease by following the working configurations and examples provided below.\nIf you just happened onto this tutorial, you will gain a decent understanding of mutation testing. Please see here for a definition of the mutation test.","title":"How  Angular Supports Mutation Testing With Example"},{"content":"Introduction This tutorial will help you understand the basics of unit testing for Angular HttpClient. Angular includes a testing module named HttpClientTestingModule that provides an HTTP mocking service, HttpTestingController to intercept the HTTP request and provide a mock response for it.\nSetup We begin by writing a service to fetch blogs from an application server.\nUse the following Angular cli commands to generate a service.\nGenerate a module ng g module blogs Generate a service ng g service blogs/blog Now create the following classes inside the app folder.\nBlog model class blog.ts export class Blog { title: string = \u0026#34;\u0026#34;; content: string = \u0026#34;\u0026#34;; createdAt: Date = new Date(); author: string = \u0026#34;\u0026#34;; } Blog Service blog.service.ts import { HttpClient } from \u0026#39;@angular/common/http\u0026#39;; import { Injectable } from \u0026#39;@angular/core\u0026#39;; import { Observable } from \u0026#39;rxjs\u0026#39;; import { Blog } from \u0026#39;./blog\u0026#39;; @Injectable({ providedIn: \u0026#39;root\u0026#39; }) export class BlogService { static readonly API_ENDPOINT = \u0026#34;http://localhost:8090/api/blogs\u0026#34;; constructor(private http: HttpClient) { } public fetchBlogs(): Observable\u0026lt;Blog[]\u0026gt; { return this.http.get\u0026lt;Blog[]\u0026gt;(BlogService.API_ENDPOINT); } } Now we have the basic building blocks of the application. Next, we can write unit tests to verify HTTP client communication between the Angular application and API server. Write Unit Test Case Create a unit test case file as follows and import the HTTP testing module and its controller.\nblog.service.spec.ts import { HttpClientTestingModule, HttpTestingController} from \u0026#39;@angular/common/http/testing\u0026#39; HttpClient Testing Module The Angular HTTP testing module provides a class named HttpTestingController which intercepts any HTTP request initiated by an Angular application. It also provides the stub response or error message to the HTTP request.\nIn nutshell, it creates a mock server with the desired response for a particular HTTP request. Next, create an instance of the HTTP testing controller to emulate mock http calls.\nbeforeEach(() =\u0026gt; { TestBed.configureTestingModule({ imports:[HttpClientTestingModule] }); service = TestBed.inject(BlogService); httpCtrl = TestBed.inject(HttpTestingController); }); Unit Test For Success Response it(\u0026#39;Should return blogs from Http Get call.\u0026#39;, () =\u0026gt; { service.fetchBlogs() .subscribe({ next: (response) =\u0026gt; { expect(response).toBeTruthy(); expect(response.length).toBeGreaterThan(1); } }); }); The above snippet executes the blog service, then accepts the response and verifies it. As stated earlier, HTTP calls are intercepted by HttpTestingController and return a successful response with a 200 status code.\nCreate success response First, we need to create a mock HTTP request handler which will intercept the request originated for http://localhost:8090/api/blogs URL.\nconst mockHttp = httpCtrl.expectOne(\u0026#39;http://localhost:8090/api/blogs\u0026#39;); const httpRequest = mockHttp.request; This will acquire the handler for the HTTP request. We can use it to validate the request\u0026rsquo;s method type and send a mock response.\nexpect(httpRequest.method).toEqual(\u0026#34;GET\u0026#34;); mockHttp.flush(BLOG_RESPONSE); Error Response The unit test case for HTTP error is shown in the snippet below.\nit(\u0026#39;Should return error message for Blog Http request.\u0026#39;, ()=\u0026gt;{ service.fetchBlogs() .subscribe({ error: (error) =\u0026gt; { expect(error).toBeTruthy(); expect(error.status).withContext(\u0026#39;status\u0026#39;).toEqual(401); } }); const mockHttp = httpCtrl.expectOne(BlogService.API_ENDPOINT); const httpRequest = mockHttp.request; mockHttp.flush(\u0026#34;error request\u0026#34;, { status: 401, statusText: \u0026#39;Unathorized access\u0026#39; }); }); Here we flush the error message with an HTTP 401 status code. And while subscribing, we bind the request to the error block and verify it.\nComplete Unit Test import { TestBed } from \u0026#39;@angular/core/testing\u0026#39;; import { HttpClientTestingModule, HttpTestingController } from \u0026#39;@angular/common/http/testing\u0026#39; import { BlogService } from \u0026#39;./blog.service\u0026#39;; describe(\u0026#39;BlogService\u0026#39;, () =\u0026gt; { let service: BlogService; let httpCtrl: HttpTestingController; const BLOG_RESPONSE = [ { title: \u0026#34;How to create service in Angular\u0026#34;, content: \u0026#34;Lorem ipsum is placeholder text commonly used in the graphic, print, and publishing industries for previewing layouts and visual mockups.\u0026#34;, createdAt: Date.now(), author: \u0026#34;Zainul\u0026#34; }, { title: \u0026#34;How to create module in Angular\u0026#34;, content: \u0026#34;Lorem ipsum is placeholder text commonly used in the graphic, print, and publishing industries for previewing layouts and visual mockups.\u0026#34;, createdAt: Date.now(), author: \u0026#34;Zainul\u0026#34; } ]; beforeEach(() =\u0026gt; { TestBed.configureTestingModule({ imports: [HttpClientTestingModule] }); service = TestBed.inject(BlogService); httpCtrl = TestBed.inject(HttpTestingController); }); it(\u0026#39;should be created\u0026#39;, () =\u0026gt; { expect(service).toBeTruthy(); }); it(\u0026#39;Should return blogs from Http Get call.\u0026#39;, () =\u0026gt; { service.fetchBlogs() .subscribe({ next: (response) =\u0026gt; { expect(response).toBeTruthy(); expect(response.length).toBeGreaterThan(1); } }); const mockHttp = httpCtrl.expectOne(BlogService.API_ENDPOINT); const httpRequest = mockHttp.request; expect(httpRequest.method).toEqual(\u0026#34;GET\u0026#34;); mockHttp.flush(BLOG_RESPONSE); }); it(\u0026#39;Should return error message for Blog Http request.\u0026#39;, () =\u0026gt; { service.fetchBlogs() .subscribe({ error: (error) =\u0026gt; { expect(error).toBeTruthy(); expect(error.status).withContext(\u0026#39;status\u0026#39;).toEqual(401); } }); const mockHttp = httpCtrl.expectOne(BlogService.API_ENDPOINT); const httpRequest = mockHttp.request; mockHttp.flush(\u0026#34;error request\u0026#34;, { status: 401, statusText: \u0026#39;Unathorized access\u0026#39; }); }); }); Conclusion Developers are under the impression that they need a production-ready API server to test their Angular application, but it is a half-truth. Rather, we just need to verify the HTTP client communication, which could be served by the mock server and the Angular HTTP testing module does exactly the same.\nSource Code You can find source code used in this tutorial on Github page.\n","permalink":"https://www.zainabed.com/2022/07/angular-getting-started-with-httpclient-unit-testing.html/","summary":"Introduction This tutorial will help you understand the basics of unit testing for Angular HttpClient. Angular includes a testing module named HttpClientTestingModule that provides an HTTP mocking service, HttpTestingController to intercept the HTTP request and provide a mock response for it.\nSetup We begin by writing a service to fetch blogs from an application server.\nUse the following Angular cli commands to generate a service.\nGenerate a module ng g module blogs Generate a service ng g service blogs/blog Now create the following classes inside the app folder.","title":"Angular: Getting Started With Httpclient Unit Testing"},{"content":"Introduction This tutorial will help you to log all level messages into console using Log4j plugin.\nIn previous tutorial we have seen how to setup the log4j plugin in Maven and simple logging application. If you need to understand the basic of Log4J the visit previous tutorial.\nWhat we will do in this tutorial We saw in the previous tutorial that Log4J\u0026rsquo;s default configuration set the logging level to Error, causing it to log only errors and fatal messages to the console.\nTo overcome this problem, we need to override the default configuration. To do so, we need to write a Log4j configuration file named Log4j2.xml and update the correct logging level.\nLog4j supports YAML, JSON, and XML file formats for its configuration files. For this tutorial we are using Log4j2.xml\nSample Log4j2.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Configuration status=\u0026#34;ERROR\u0026#34;\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;Console name=\u0026#34;Console\u0026#34; target=\u0026#34;SYSTEM_OUT\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026#34;/\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; ` \u0026lt;Root level=\u0026#34;ERROR\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt;  Note : Place the Log4j2.xml file in the classpath, or in the src/resources directory for Maven projects.\n Console Appender The Appender configuration tag tells where to log the messages, it could be console or file.\nThe Console appender sets out a layout to log the message by defining the pattern. The pattern can include date and time, level of message, message itself, etc.\n target : Either SYSTEM_OUT or SYSTEM_ERR. The default is SYSTEM_OUT. pattern : The log messages are formatted using a combination of literals, conversion characters, and format modifiers, according to the pattern.  Sample Code import org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; public class MainApp { public static void main(String[] args) { Logger logger = LogManager.getLogger(); printLoggingLevels(logger); } private static void printLoggingLevels(Logger logger) { logger.trace(\u0026#34;logging trace level\u0026#34;); logger.debug(\u0026#34;logging debug level\u0026#34;); logger.info(\u0026#34;logging info level\u0026#34;); logger.warn(\u0026#34;logging warn level\u0026#34;); logger.error(\u0026#34;logging error level\u0026#34;); logger.fatal(\u0026#34;logging fatal level\u0026#34;); } } You will get the following output on the console as you run the application.\n02:29:50.976 [main] ERROR com.zainabed.tutorials.logging.MainApp - logging error level 02:29:50.979 [main] FATAL com.zainabed.tutorials.logging.MainApp - logging fatal level Still, we get only Error and Fatal messages even after creating the custom configuration file.\nTo understand the problem, we need to learn the logging level defined for Log4j.\nLogging level filter revisit Log4j has the following filter mechanism.\nAll \u0026lt; Trace \u0026lt; Debug \u0026lt; Info \u0026lt; Warn \u0026lt; Error \u0026lt; Fatal\nIf the logging level is set to be Debug, then Debug, info, warning, error, and fatal messages will be logged into the console.\nWhen the logging level is set to \u0026ldquo;Error,\u0026rdquo; both the Error and Fatal messages are displayed.\nSo we need to update the Root level from Error to Debug.\nUpdated Log4j2.xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Configuration status=\u0026#34;ERROR\u0026#34;\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;Console name=\u0026#34;Console\u0026#34; target=\u0026#34;SYSTEM_OUT\u0026#34;\u0026gt; \u0026lt;PatternLayout pattern=\u0026#34;%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\u0026#34;/\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; ` \u0026lt;Root level=\u0026#34;DEBUG\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;Console\u0026#34;/\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; Here we have updated the Root level from Error to Debug.\nRerun the application and you will get the following output.\n02:32:27.675 [main] DEBUG com.zainabed.tutorials.logging.MainApp - logging debug level 02:32:27.680 [main] INFO com.zainabed.tutorials.logging.MainApp - logging info level 02:32:27.680 [main] WARN com.zainabed.tutorials.logging.MainApp - logging warn level 02:32:27.680 [main] ERROR com.zainabed.tutorials.logging.MainApp - logging error level 02:32:27.680 [main] FATAL com.zainabed.tutorials.logging.MainApp - logging fatal level Conclusion In this tutorial, we learned the importance of the Log4j2.xml configuration. How to control the logging level and medium of output .\nIn the next tutorial, we will learn how to log the messages into a file.\nYou can find the source code on Github.\n","permalink":"https://www.zainabed.com/2022/06/log4j-how-to-log-message-to-console.html/","summary":"Introduction This tutorial will help you to log all level messages into console using Log4j plugin.\nIn previous tutorial we have seen how to setup the log4j plugin in Maven and simple logging application. If you need to understand the basic of Log4J the visit previous tutorial.\nWhat we will do in this tutorial We saw in the previous tutorial that Log4J\u0026rsquo;s default configuration set the logging level to Error, causing it to log only errors and fatal messages to the console.","title":"Log4j How to Log Message to Console"},{"content":"Introduction For Java applications, Log4j is a commonly used and trusted logging tool. When an application is deployed to an application server, logging is a must-have feature.\nIn this tutorial, we\u0026rsquo;ll see how to set up Log4j for a simple Java application.\nYou can find all code related to this tutorial inside GitHub project.\nWhy do we need Logging Logging is an important part of the application since it records user actions, input requests and output responses, error messages, and more.\nThis information aids in the understanding of the application both inside and outside of it, as well as providing faster feedback or support for any issues that may occur during the application\u0026rsquo;s execution.\nMaven configuration Add following dependencies into pom.xml\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.logging.log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.17.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.logging.log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.17.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt;  Note : Choose the latest version of Log4J to guard against any unwanted vulnerabilities.\n Sample code Now lets add few log message and see the result.\nimport org.apache.logging.log4j.LogManager; import org.apache.logging.log4j.Logger; public class MainApp { public static void main(String[] args) { Logger logger = LogManager.getLogger(); printLoggingLevels(logger); } private static void printLoggingLevels(Logger logger) { logger.trace(\u0026#34;logging trace level\u0026#34;); logger.debug(\u0026#34;logging debug level\u0026#34;); logger.info(\u0026#34;logging info level\u0026#34;); logger.warn(\u0026#34;logging warn level\u0026#34;); logger.error(\u0026#34;logging error level\u0026#34;); logger.fatal(\u0026#34;logging fatal level\u0026#34;); } } Logging levels All of the logging levels available in the Log4j package are demonstrated in the code sample above.\nLet\u0026rsquo;s look at what each level does.\n Trace : A fine-grained message that records all traces of the application\u0026rsquo;s flow. Debug : Messages used to debug an application\u0026rsquo;s behaviour during development. Info : Common application flow message. Warn : An event that may result in an error. Error : An exception occurred within the application, which may be recovered. Fatal : An application encounters an error that cannot be recovered from.  When we execute the application, Log4J starts logging into the console.\n02:34:02.491 [main] ERROR com.zainabed.tutorials.logging.MainApp - logging error level 02:34:02.504 [main] FATAL com.zainabed.tutorials.logging.MainApp - logging fatal level As we can see it logs only Error \u0026amp; Fatal level messages only. This happens because of Logging level filtering.\nLogging level filter Log4j has the following filter mechanism.\nAll \u0026lt; Trace \u0026lt; Debug \u0026lt; Info \u0026lt; Warn \u0026lt; Error \u0026lt; Fatal\nIf the logging level is set to be info, then only info, warning, error, and fatal messages will be logged into the console.\nWhen the logging level is set to \u0026ldquo;Error\u0026rdquo; both the Error and Fatal messages are displayed.\nThe default logging level is Error for applications. That is why we see only Error and Fatal log messages.\nTo override the default behavior, we need to add the Log4j2.xml configuration file and provide an appropriate logging level to log relevant messages.\nConclusion Every application requires a logging method to record the flow and behaviour of the application. Log4j is a widely adopted tool to provide such a facility.\nLog4j is extremely configurable, and application-specific parameters are set via Log4j2.xml.\n","permalink":"https://www.zainabed.com/2022/05/getting-started-with-log4j.html/","summary":"Introduction For Java applications, Log4j is a commonly used and trusted logging tool. When an application is deployed to an application server, logging is a must-have feature.\nIn this tutorial, we\u0026rsquo;ll see how to set up Log4j for a simple Java application.\nYou can find all code related to this tutorial inside GitHub project.\nWhy do we need Logging Logging is an important part of the application since it records user actions, input requests and output responses, error messages, and more.","title":"Getting Started With Log4j"},{"content":"Introduction In this tutorial we will see how to setup the JaCoCo plugin to generate a code coverage report for a Maven project.\nIn order to generate a unit test coverage report, we should have sufficient unit test cases in our application. For this tutorial, I am referring to a Maven project which has a string manipulation method.\nYou can find this project at this GitHub location.\nThere are a few steps that need to be taken to produce the report.\nInstall the Maven JaCoCo plugin. Insert the following code into pom.xml.\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.jacoco\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jacoco-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.8.2\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;prepare-agent\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;report\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;test\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;report\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; Add a Unit Test Create a class as StringUtil.java and add following snippet.\npackage com.zainabed.tutorials; public class StringUtil { public int findIntegerCount(String input) { if (input == null) { return 0; } int count = 0; for (int index = 0; index \u0026lt; input.length(); index++) { char character = input.charAt(index); if (character \u0026gt;= 48 \u0026amp;\u0026amp; character \u0026lt;= 57) { count++; } } return count; } } Next, create a unit test class for above class as StringUtilTest.java.\npackage com.zainabed.tutorials; import org.junit.jupiter.api.Test; import static org.junit.jupiter.api.Assertions.assertEquals; class StringUtilTest { @Test void should_return_count_of_numeric_value() { StringUtil stringUtil = new StringUtil(); String input = \u0026#34;1name34sample;\u0026#34;; assertEquals(3, stringUtil.findIntegerCount(input)); input = \u0026#34;namesample\u0026#34;; assertEquals(0, stringUtil.findIntegerCount(input)); } } Now execute the maven build. It will generate the code coverage report.\nmvn clean install Build will generate following code coverage result\nYou can configure different goals of the JaCoCo plugin, such as restricting code coverage percentage.\nOur application has 75% branch coverage so far. Let\u0026rsquo;s use the following snippet to configure the coverage limit by setting the execution configuration of the JaCoCo plugin and setting the value to 80%.\n\u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;coverage-check\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;test\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;check\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;rules\u0026gt; \u0026lt;rule\u0026gt; \u0026lt;element\u0026gt;CLASS\u0026lt;/element\u0026gt; \u0026lt;limits\u0026gt; \u0026lt;limit\u0026gt; \u0026lt;counter\u0026gt;BRANCH\u0026lt;/counter\u0026gt; \u0026lt;value\u0026gt;COVEREDRATIO\u0026lt;/value\u0026gt; \u0026lt;minimum\u0026gt;80%\u0026lt;/minimum\u0026gt; \u0026lt;/limit\u0026gt; \u0026lt;/limits\u0026gt; \u0026lt;/rule\u0026gt; \u0026lt;/rules\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; Now with this configuration build will fail.\nWe can make the build pass by improving the branch code coverage. Let us update the unit test as follows.\n@Test void should_return_zero_for_empty_string() { StringUtil stringUtil = new StringUtil(); assertEquals(0, stringUtil.findIntegerCount(null)); } Build the application again.\nmvn clean install Build will result the success as shown in following diagram\nAnd the new report will include the code coverage above 80%.\nConclusion Code coverage is a useful asset to improve unit testing of applications and JaCoCo facilitates it efficiently.\n","permalink":"https://www.zainabed.com/2022/05/maven-create-jacoco-code-coverage-report.html/","summary":"Introduction In this tutorial we will see how to setup the JaCoCo plugin to generate a code coverage report for a Maven project.\nIn order to generate a unit test coverage report, we should have sufficient unit test cases in our application. For this tutorial, I am referring to a Maven project which has a string manipulation method.\nYou can find this project at this GitHub location.\nThere are a few steps that need to be taken to produce the report.","title":"Maven Create Jacoco Code Coverage Report"},{"content":"What is RestTemplet? RestTemplate is a HTTP Client library that provides basic APIs for executing different HTTP type requests.\nRestTemplate is one of the HTTP libraries available on the market.\nThe Spring Boot team designed and maintains it.\nAs previously said, it is a client library, which means it may be utilised in our application as a stand-alone dependency. To utilise it, you don\u0026rsquo;t require a complete Spring boot application.\nIt\u0026rsquo;s suitable for use in simple Java applications as well as other frameworks such as Micronaut, Play and others.\nSetup Add RestTemplate dependency to project, for this tutorial I am creating a simple java application to consume HTTP request and a node application to provide HTTP service.\nFor Gradle build tool Add the following dependency in the build.gradle file.\n// https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-web implementation group: \u0026#39;org.springframework.boot\u0026#39;, name: \u0026#39;spring-boot-starter-web\u0026#39;, version: \u0026#39;2.6.3\u0026#39; This will provide classes to create instance of RestTemplate.\nRestTemplate restTemplate = new RestTemplate(); REST APIs Node.js has a useful library that converts a json file to a RESTful service.\nInstall the npm library as\nnpm install json-server --save-dev Now define the JSON structure for the HTTP service.\ncreate db.json file and add following snippet\n{ \u0026#34;projects\u0026#34;: [ { \u0026#34;id\u0026#34; : 1, \u0026#34;name\u0026#34; : \u0026#34;RestTemplate\u0026#34;, \u0026#34;description\u0026#34; : \u0026#34;Project to demonstrate workflow of RestTemplate\u0026#34; }] } Now, run server as\nnode_modules/.bin/json-server db.json  Note: Use following command to find location of node_module executable npm bin\n Model Define any POJO class which is use to exchange the request and response.\npublic class ProjectModel { private Integer id; private String name; private String description; public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } public String getDescription() { return description; } public void setDescription(String description) { this.description = description; } @Override public String toString() { return \u0026#34;{id: \u0026#34; + id + \u0026#34;, name: \u0026#34; + name + \u0026#34;, description: \u0026#34; + description + \u0026#34;}\u0026#34;; } } HTTP Get Request Use following snippet to get single records.\n// Instantiate RestTemplate RestTemplate restTemplate = new RestTemplate(); String apiEndpoint = \u0026#34;http://localhost:3000/projects\u0026#34;; // HTTP GET single record ResponseEntity\u0026lt;ProjectModel\u0026gt; entity = restTemplate.getForEntity(apiEndpoint + \u0026#34;/1\u0026#34;, ProjectModel.class); ProjectModel record = entity.getBody(); System.out.println(\u0026#34;Fetch single records\u0026#34;); System.out.println(record); First we defined restTemplate instance and endpoint to establish HTTP communication. getForEntity method will fetch the resource and convert it into an appropriate Java class. Here, it is a ProjectModel class.\nUse following snippet to fetch all records.\n// HTTP GET all records System.out.println(\u0026#34;Fetch all records\u0026#34;); ResponseEntity\u0026lt;List\u0026gt; records = restTemplate.getForEntity(apiEndpoint, List.class); records.getBody().forEach(System.out::println); This will create a list of Java objects. One thing to notice here is that the result is a list of Java objects. It is necessary to iterate the list and cast each object in order to convert it into a project model.\nThe Spring framework provides a handy technique to cast a list of objects to avoid this complexity.\n// HTTP GET all with casting of entity ParameterizedTypeReference\u0026lt;List\u0026lt;ProjectModel\u0026gt;\u0026gt; typeReference = new ParameterizedTypeReference\u0026lt;List\u0026lt;ProjectModel\u0026gt;\u0026gt;() { }; ResponseEntity\u0026lt;List\u0026lt;ProjectModel\u0026gt;\u0026gt; responseEntity = restTemplate.exchange(apiEndpoint, HttpMethod.GET, null, typeReference); List\u0026lt;ProjectModel\u0026gt; projectModels = responseEntity.getBody(); projectModels.forEach(System.out::println); HTTP POST Request //HTTP POST Request ProjectModel projectModel = new ProjectModel(); projectModel.setName(\u0026#34;Blogger App\u0026#34;); projectModel.setDescription(\u0026#34;Blog application to publish blogpost\u0026#34;); ResponseEntity\u0026lt;ProjectModel\u0026gt; response = restTemplate.postForEntity(apiEndpoint, projectModel, ProjectModel.class); System.out.println(response.getBody()); The postForEntity function takes three arguments, API endpoint, the other payload and its class type.\nHere we have not set the id of the ProjectModel. It should be created by the server and you should get it from the response object.\nHTTP PUT Request //HTTP PUT request projectModel = response.getBody(); projectModel.setName(\u0026#34;Blog post app\u0026#34;); HttpHeaders httpHeaders = new HttpHeaders(); httpHeaders.setContentType(MediaType.APPLICATION_JSON); httpHeaders.setAccept(Arrays.asList(MediaType.APPLICATION_JSON)); HttpEntity\u0026lt;ProjectModel\u0026gt; requestEntity = new HttpEntity\u0026lt;ProjectModel\u0026gt;(projectModel, httpHeaders); response = restTemplate.exchange(apiEndpoint + \u0026#34;/\u0026#34; + projectModel.getId(), HttpMethod.PUT, requestEntity, ProjectModel.class); System.out.println(\u0026#34;PUT response\u0026#34;); System.out.println(response.getBody()); The above example shows another way to communicate with an API server.\nThe exchange method requires HttpEntity to pass request information to the server, and it also includes HTTP header information.\nHTTP Delete Request // HTTP Delete request restTemplate.delete(apiEndpoint + \u0026#34;/\u0026#34; + projectModel.getId()); There is no return type for this method, and even if you use the exchange method to perform an HTTP DELETE, you will get an empty response object.\nConclusion We went over the basic HTTP Verbs in this post and used RestTemplate to compose requests using all of them.\nAll of these examples and code snippets were implemented and can be found on GitHub .\n","permalink":"https://www.zainabed.com/2022/04/spring-boot-resttemplate-guide-with-example.html/","summary":"What is RestTemplet? RestTemplate is a HTTP Client library that provides basic APIs for executing different HTTP type requests.\nRestTemplate is one of the HTTP libraries available on the market.\nThe Spring Boot team designed and maintains it.\nAs previously said, it is a client library, which means it may be utilised in our application as a stand-alone dependency. To utilise it, you don\u0026rsquo;t require a complete Spring boot application.","title":"Spring Boot Resttemplate Guide With Example"},{"content":"Introdcution In this tutorial, we\u0026rsquo;ll go over how to fix Git commit messages that have been committed to a local or remote Git repository.\nReason to change commit message? When working with Git, there could be several reasons to update the commit message. Some of the common reasons are as follows\n Message contains a typo. Missing intent of commit. Remove any confidential information. Correct issue ticket number to connect to an issue tracker such as Jira.  Solution The reason could be anything, but you should be aware of the command to update the commit message at any point in the development of your application.\nLet\u0026rsquo;s take a look at the solution for a single commit message.\nLocal commit Assume you perform the following Git operation.\n$ git add -A $ git commit -m \u0026#34;[PROJECT-99] - Added user profile module.\u0026#34; And after you realise that the issue number for the current commit is incorrect and needs to be corrected. That\u0026rsquo;s the story of Project 100.\nYou can correct it using the method outlined below.\n$ git commit --amend -m \u0026#34;[PROJECT-100] - Added user profile module.\u0026#34; If you look at git log then updated message will reflect in it.\ncommit 75c82d058b32b82b5724618c816684c5aaa59022 (HEAD -\u0026gt; master) Author: User Date: Tue Apr 19 01:08:53 2022 -0400 [PROJECT-100] - Added user profile module. Remote commit The following approach can be used to correct the latest pushed commit.\n$ git commit --amend -m \u0026#34;[PROJECT-101] - Added user profile module.\u0026#34; And git log history will show the latest updated message as\ncommit 7e2937ff912a5c512036c9c1e4befb8a4512a9a3 (HEAD -\u0026gt; master) Author: User Date: Tue Apr 19 01:08:53 2022 -0400 [PROJECT-101] - Added user profile module. However, because this change occurs in your current working directory, you must run the command below to update the remote repository.\n$ git push --force origin master When you look at the remote repository, you\u0026rsquo;ll notice that the most recent message has been added to it.\nChanging an Older or Multiple Commits If you ever need to change multiple commits for some reason, use Git interactive rebase.\nGit rebase rewrites the history, and it is strongly advised not to use rebase unless there is a compelling reason to use it.\nUse the command git rebase -i HEAD~N, where N represents the number of commits to update. As an example,\n$ git rebase -i HEAD~3 It will launch an editor and allow you to choose three commits from the history.\npick 6bfbd01 Added Cucumber + Gradle project pick 603981a Added Spring Boot SQL Logging project. pick 7e2937f [PROJECT-101] - Added user profile module. # Rebase 0d7b04f..7e2937f onto 0d7b04f (3 commands) Navigate to the line you want to change and replace the pick word with the reword.\npick 6bfbd01 Added Cucumber + Gradle project reword 603981a Added Spring Boot SQL Logging project. reword 7e2937f [PROJECT-101] - Added user profile module. Save and exit the editor now. For each reword commit, Git will launch a new editor.\n[Project-99] Added Spring Boot SQL Logging project. Save and exit the editor after updating the commit message.\nThis will bring your local git history up to date. Use the following command to update remote Git history.\n$ git push --force origin master It will update remote Git history as.\nConclusion Use the git commit --amend command to change the most recent commit message. Use git rebase -i HEAD~N to change older or multiple commit messages.\nDon\u0026rsquo;t change remote commits using rebase because it could cause a lot of problems for your colleagues.\n","permalink":"https://www.zainabed.com/2022/04/how-to-change-a-git-commit-message.html/","summary":"Introdcution In this tutorial, we\u0026rsquo;ll go over how to fix Git commit messages that have been committed to a local or remote Git repository.\nReason to change commit message? When working with Git, there could be several reasons to update the commit message. Some of the common reasons are as follows\n Message contains a typo. Missing intent of commit. Remove any confidential information. Correct issue ticket number to connect to an issue tracker such as Jira.","title":"How to Change a Git Commit Message"},{"content":"Introduction This tutorial will demonstrate how to enable and disable SQL log statements in a Spring Boot application in order to debug SQL flow.\nProblem You will frequently need to debug the SQL statement while developing a Spring Boot application with a SQL database.\nSQL debug logs can assist you figure out what\u0026rsquo;s wrong with JPA statements and whether or not there\u0026rsquo;s a problem with database connectivity.\nExample If you\u0026rsquo;ve built custom Spring data JPA methods and need to know what SQL statement is being utilized behind them,\nreturn repository.findByUsernameIn(usernames); Then you can enable Hibernet debug mode to log SQL statements.\nSolution Update the application.yml file with the Hibernet configuration as\nlogging: level: org: hibernate: DEBUG or application.properties as\nlogging.level.org.hibernate=DEBUG The SQL statement will appear in the application logs after modifying the configuration file and restarting the application.\n2022-04-07 08:41:45.118 DEBUG 14561 --- [nio-8080-exec-1] org.hibernate.SQL : select user0_.id as id1_0_, user0_.password as password2_0_, user0_.username as username3_0_ from user user0_ where user0_.username in (?) Spring Boot Profiles This setup is great for debugging and testing your application while you are building or improving its features, but it\u0026rsquo;s not appropriate for staging or production situations.\nTo turn off the debugging logs in the production environment, you should prefer to use Spring boot profiles.\n application.properties : Local machine application-dev.properties: Development environment. application-stage.properties: Stage/Test environment application-prod.properties: Production environment  Inside application-prod.properties, specifically turn off SQL debug logs, like\nlogging.level.org.hibernate=OFF  Note: It is not a rule to name your application properties file as mentioned in this tutorial. You are free to give it whatever name you like.\n Conclusion SQL debugging can be activated or deactivated by application configuration. The production environment should explicitly disable this configuration.\nYou can access tutorial code from Github page.\n","permalink":"https://www.zainabed.com/2022/04/how-to-enable-sql-logs-in-spring-boot-application.html/","summary":"Introduction This tutorial will demonstrate how to enable and disable SQL log statements in a Spring Boot application in order to debug SQL flow.\nProblem You will frequently need to debug the SQL statement while developing a Spring Boot application with a SQL database.\nSQL debug logs can assist you figure out what\u0026rsquo;s wrong with JPA statements and whether or not there\u0026rsquo;s a problem with database connectivity.\nExample If you\u0026rsquo;ve built custom Spring data JPA methods and need to know what SQL statement is being utilized behind them,","title":"How to Enable Sql Logs in Spring Boot Application"},{"content":"Introduction This tutorial will help you configure Cucumber into a Java project using the Gradle build tool.\nCucumber is a test automation tool that supports Behavior-Driven Development (BDD). It is written in plain English text called \u0026ldquo;Gherkin.\u0026rdquo; Cucumber enables you to write test cases that anyone can easily understand, regardless of their technical knowledge.\nSetup First, create a Gradle project using the gradle init command.\ngradle init Complete the Gradle wizard to create a project.\nNow update the gradle.build file to add the Gradle Cucumber dependency.\ntestImplementation \u0026#39;io.cucumber:cucumber-java8:7.0.0\u0026#39; This will add Cucumber implementation to your project.\nTask Configuration Add the following configuration to gradle.build This will enable the Cucumber runtime to execute BDD test cases.\nconfigurations { cucumberRuntime { extendsFrom testImplementation } } Create a new custom task to execute Cucumber\ntask cucumber() { dependsOn assemble, testClasses doLast { javaexec { main = \u0026#34;io.cucumber.core.cli.Main\u0026#34; classpath = configurations.cucumberRuntime + sourceSets.main.output + sourceSets.test.output args = [ \u0026#39;--plugin\u0026#39;, \u0026#39;pretty\u0026#39;, \u0026#39;--plugin\u0026#39;, \u0026#39;html:target/cucumber-report.html\u0026#39;, \u0026#39;--glue\u0026#39;, \u0026#39;com.zainabed.cucumber.bdd\u0026#39;, \u0026#39;src/test/resources\u0026#39;] } } }  NOTE: com.zainabed.cucumber.bdd is reference to a package name, You should put in your project package name..\n Cucumber Options/Args\n glue: Project package name where you define the glue code. plugin: Plugins which you want to add in the project. pretty: Generate a pretty report html: Generate Cucumber HTML report. src/test/resources: Location of feature files.  Feature File Cucumber interprets the Gherkins feature file and executes the glue code associated with it. Therefore, create a features folder inside the test resources section src/test/resources/ and add the Gherkin feature which gets executed by cucumber.\nFeature:User Registration User will initiate registration request to system and system will validate the information and add user to system Scenario:Basic Flow Given User visit registration When User enter his registration details Then System validate the information And User get registered Run the Task Next, run the following command to execute Cucumber test cases.\n./gradlew cucumber It will fail and give you the glue code that you need to add to your project like this.\nTask :app:cucumber FAILED Scenario: Basic Flow # src/test/resources/features/user-registration.feature:5 Given User visit registration When User enter his registration details Then System validate the information And User get registered Undefined scenarios: You can implement missing steps with the snippets below: Given(\u0026#34;User visit registration\u0026#34;, () -\u0026gt; { // Write code here that turns the phrase above into concrete actions throw new io.cucumber.java8.PendingException(); }); When(\u0026#34;User enter his registration details\u0026#34;, () -\u0026gt; { // Write code here that turns the phrase above into concrete actions throw new io.cucumber.java8.PendingException(); }); Then(\u0026#34;System validate the information\u0026#34;, () -\u0026gt; { // Write code here that turns the phrase above into concrete actions throw new io.cucumber.java8.PendingException(); }); Then(\u0026#34;User get registered\u0026#34;, () -\u0026gt; { // Write code here that turns the phrase above into concrete actions throw new io.cucumber.java8.PendingException(); }); Glue Code In order to fix the cucumber task error, we need to provide glue code, which is nothing but a Java class.\nCreate a new Java file named UserRegistrationBDD.java inside bdd package and add the above code into it.\npackage com.zainabed.cucumber.bdd; import io.cucumber.java8.En; public class UserRegistrationBDD implements En { public UserRegistrationBDD() { Given(\u0026#34;User visit registration\u0026#34;, () -\u0026gt; { // Write code here that turns the phrase above into concrete actions  throw new io.cucumber.java8.PendingException(); }); When(\u0026#34;User enter his registration details\u0026#34;, () -\u0026gt; { // Write code here that turns the phrase above into concrete actions  throw new io.cucumber.java8.PendingException(); }); Then(\u0026#34;System validate the information\u0026#34;, () -\u0026gt; { // Write code here that turns the phrase above into concrete actions  throw new io.cucumber.java8.PendingException(); }); Then(\u0026#34;User get registered\u0026#34;, () -\u0026gt; { // Write code here that turns the phrase above into concrete actions  throw new io.cucumber.java8.PendingException(); }); } } Add some business logic to it, then rerun it.\n Note: Cucumber Java 8 dependency uses constructor and English \u0026ldquo;En\u0026rdquo; interface to implement glue code.\n Add your business logic and assertions to execute features.\nRe-Run the Cucumber Task At the end, execute the cucumber tasks.\nTask :app:cucumber Scenario: Basic Flow # src/test/resources/features/user-registration.feature:5 Given User visit registration # com.zainabed.cucumber.bdd.UserRegistrationBDD.\u0026lt;init\u0026gt;(UserRegistrationBDD.java:9) When User enter his registration details # com.zainabed.cucumber.bdd.UserRegistrationBDD.\u0026lt;init\u0026gt;(UserRegistrationBDD.java:13) Then System validate the information # com.zainabed.cucumber.bdd.UserRegistrationBDD.\u0026lt;init\u0026gt;(UserRegistrationBDD.java:17) And User get registered # com.zainabed.cucumber.bdd.UserRegistrationBDD.\u0026lt;init\u0026gt;(UserRegistrationBDD.java:21) 1 Scenarios (1 passed) 4 Steps (4 passed) Conclusion This tutorial demonstrated the setup and configuration of the Cucumber test framework using the Gradle build tool.\nFull source can be found on the Github page.\n","permalink":"https://www.zainabed.com/2022/04/cucumber-setup-using-gradle.html/","summary":"Introduction This tutorial will help you configure Cucumber into a Java project using the Gradle build tool.\nCucumber is a test automation tool that supports Behavior-Driven Development (BDD). It is written in plain English text called \u0026ldquo;Gherkin.\u0026rdquo; Cucumber enables you to write test cases that anyone can easily understand, regardless of their technical knowledge.\nSetup First, create a Gradle project using the gradle init command.\ngradle init Complete the Gradle wizard to create a project.","title":"Cucumber Setup Using Gradle"},{"content":"Introduction In this tutorial, we will create a Micronaut application using Gradle.\nWhat you will need  Java installed on your machine Gradle installed on your machine Text Editor  Steps First create your project folder, we will make a folder called \u0026ldquo;micronaut-project\u0026rdquo; for this tutorial.\nThe second step is to add the build.gradle file inside the project folder.\nThis will contain a script to build the Micronaut application.\nNow update the build.gradle file.\nAdd following plugin\nplugins { id(\u0026#34;com.github.johnrengelman.shadow\u0026#34;) version \u0026#34;7.1.1\u0026#34; id(\u0026#34;io.micronaut.application\u0026#34;) version \u0026#34;3.2.0\u0026#34; } This will help to build application executable jars.\nNext, add dependencies.\ndependencies { annotationProcessor(\u0026#34;io.micronaut:micronaut-http-validation\u0026#34;) implementation(\u0026#34;io.micronaut:micronaut-http-client\u0026#34;) implementation(\u0026#34;io.micronaut:micronaut-jackson-databind\u0026#34;) implementation(\u0026#34;io.micronaut:micronaut-runtime\u0026#34;) implementation(\u0026#34;jakarta.annotation:jakarta.annotation-api\u0026#34;) runtimeOnly(\u0026#34;ch.qos.logback:logback-classic\u0026#34;) implementation(\u0026#34;io.micronaut:micronaut-validation\u0026#34;) implementation(\u0026#34;io.micronaut:micronaut-http-server-netty\u0026#34;) } To download and install these dependencies, you need to configure the repository.\nrepositories { mavenCentral() } Include a micronaut task to configure the application\u0026rsquo;s runtime and Micronaut annotations.\nmicronaut { runtime(\u0026#34;netty\u0026#34;) processing { incremental(true) annotations(\u0026#34;com.tutorial.project.*\u0026#34;) } }  NOTE: com.tutorial.project is the project package name. Replace it with your project package name.\n To enable the Micornaut application starter, add the following configuration:\napplication { mainClass.set(\u0026#34;com.tutorial.project.Application\u0026#34;) }  NOTE: com.tutorial.project is the project package name. Replace it with your project package name.\n Now create Application class and add following code\npackage com.tutorial.project; import io.micronaut.runtime.Micronaut; public class Application { public static void main(String[] args) { Micronaut.run(Application.class, args); } }  NOTE: location of this file should be in micronaut-project/src/main/java/com/tutorial/project\n The last step is to create a gradle.properties file and add the following configuration.\nmicronautVersion=3.3.0 Now run the following command to build the application and create executable jars.\ngradle build It will create application jars in build/lib folder.\nUse the following command to launch the application\njava -jar build/libs/micronaut-project-all.jar You can access the source code of this tutorial on Github.\n","permalink":"https://www.zainabed.com/2022/03/getting-started-with-micronaut-using-gradle.html/","summary":"Introduction In this tutorial, we will create a Micronaut application using Gradle.\nWhat you will need  Java installed on your machine Gradle installed on your machine Text Editor  Steps First create your project folder, we will make a folder called \u0026ldquo;micronaut-project\u0026rdquo; for this tutorial.\nThe second step is to add the build.gradle file inside the project folder.\nThis will contain a script to build the Micronaut application.\nNow update the build.","title":"Getting Started With Micronaut Using Gradle"},{"content":"What is the Abstract Factory design pattern? The intent or definition of Abstract Factory is\n “Provide an interface for creating families of related or dependent objects without specifying their concrete classes”  It\u0026rsquo;s a bit of a complicated definition, so we\u0026rsquo;ll need to break it down into meaningful chunks to understand it.\n1. \u0026ldquo;Provide an interface\u0026rdquo; When we discuss the Abstract Factory, we are referring to interfaces rather than abstract classes. Essentially, this design pattern provides us with an interface, similar to those found in Java, C#, or Typescript (abstract class).\nWhy interface? Whenever we talk about any design pattern, we focus on how we will use it rather than how we will implement it.\nBecause a concrete class creates tight coupling, whereas an interface isolates it from the rest of the system, an interface is always the better choice. We can get different solutions at runtime without having to update our code.\nFor example\ninterface SecurityFactory { AuthenticationManager getAuthenticationManager(); AuthorizationManager getAuthorizationManager(); } Here we have an abstract factory which defines the behaviour of creating objects related to application security, like authentication and authorization.\nHere we can have different authentication schemes like Basic, Bearer, or Digest, and authorizations like simple or JWT.\nOur client code is unconcerned about which implementation we use, it just uses Abstract Factory interfaces to perform security-related actions.\n2. “for creating families of related or dependent objects” The second part states that the Abstract Factory, aka Interface, creates objects. Interfaces contain methods, and each method should return an object.\nAuthenticationManager getAuthenticationManager(); AuthorizationManager getAuthorizationManager(); When we call these methods, we get instances of security objects that are related to a context. Here, the context is security.\n3. “without specifying their concrete classes” The last part of the definition states that the return type of each abstract method is an interface, not a concrete class.\nIt makes sense because the Abstract Factory is an interface in and of itself, therefore the return type of each of its methods should also be an interface. Clients can now obtain many types of objects from the Abstract Factory without having to make any changes on their end.\nFor example, when I use SecurityFactory like this,\npublic TestApp(SecurityFactory securityFactory ) { AuthorizationManager authorizationManager = securityFactory.getAuthorizationManager(); if(authorizationManager.isLoggedIn()){ // allow user to access resource  }else{ // notify unauthorized user  } } Here, the object authorizationManager can represent any kind of authorization model, like basic authorization, JWT, or session based authorization.\nTo have different authorization behaviors, we don\u0026rsquo;t need to change anything on the client side. Instead, we add a different securityFactory dependency at runtime.\nAnother example would be as follow.\nvoid AuthenticateUser(String username, String password){ AuthenticationManager authManager = securityFactory.getAuthenticationManager(); if (authManager.authenticate(username, password) == true){ // User is authenticated  }else { // Invalid User  } } The authentication model in this situation could range from basic authentication to custom authentication.\nThis implementation will not impact the client code, it only knows about the interface, not its implementation.\nThe concrete implementations of SecurityFactory will be the only thing that changes inside your application, this can be done using dependency injection.\nBenefits Every application requires the construction of a number of objects, each with its own set of creation procedures.\nTo instantiate objects, some developers prefer new keywords, while others prefer dependency injection, such as singleton. The first technique leads to tight coupling, which is difficult to verify, and the second way is difficult to maintain and can lead to a verbose constructor definition.\nWhen we group all related objects of an application together, we get only a few abstract factories that are easy to manage and maintain throughout the entire application.\nAbstractFactory is easy to test. We can create mock objects and test application behaviour easily.\nAbstractFactory follows the Open/Close principle. We can change the behaviour of an application without updating any client code.\nExample Security Abstract Factory Github link.\nSecurity Abstract Factory Implementation Github link\nConclusion It is a creational pattern to create a set of related objects. Rather than creating objects with new keywords, which is difficult to maintain and verify, we should encapsulate them within creational patterns. The Abstract Factory is a great pattern to create such related items.\nPlease let me know what you think of this pattern and how you\u0026rsquo;ve implemented it in your app.\n","permalink":"https://www.zainabed.com/2020/04/abstract-factory-design-pattern-analysis.html/","summary":"What is the Abstract Factory design pattern? The intent or definition of Abstract Factory is\n “Provide an interface for creating families of related or dependent objects without specifying their concrete classes”  It\u0026rsquo;s a bit of a complicated definition, so we\u0026rsquo;ll need to break it down into meaningful chunks to understand it.\n1. \u0026ldquo;Provide an interface\u0026rdquo; When we discuss the Abstract Factory, we are referring to interfaces rather than abstract classes.","title":"Abstract Factory Design Pattern Analysis"},{"content":"Introduction Every application starts with bootstrap process which initialize application and wire it other with dependencies and configurations.\nAngularJs is not different from other application. It also starts application with bootstrap process.\nFollowing operation happens inside AngularJs bootstrap process.\n Load application module. Create dependency injector and load dependencies. Compile HTML and create scope for application.  All these steps happens inside angular.js scripting file. therefore we need to include it first. we can include it inside HEAD tag or at end of BODY tag.\n Note: Adding angular.js file at end of body tag will allow browser to load of HTML elements without any delay and afterwards load angular.js and begin bootstrapping process.\n You can get angular.js source file from https://code.angularjs.org/\n\u0026lt;script src=”https://code.angularjs.org/1.3.0/angular.js” type=”text/javascript”\u0026gt; AngularJs bootstrap process happens on document ready event.\nlets see the simple AngularJs example.\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Angular Application\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body ng-app=\u0026#34;myApp\u0026#34;\u0026gt; \u0026lt;div ng-controller=\u0026#34;myCtrl\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{{title}}\u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;https://code.angularjs.org/1.3.0/angular.js\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; //angular module  angular.module(\u0026#34;myApp\u0026#34;,[]) //controller  .controller(\u0026#34;myCtrl\u0026#34;, [\u0026#34;$scope\u0026#34;, function($scope){ $scope.title = \u0026#34;Angular Bootstrap Tutorial!\u0026#34; }]) \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Now lets look into AngularJs bootstrap process steps one by one.\nLoad application module AngularJs will look for module name which is associated with ng-app directive inside HTML page.\n\u0026lt;html ng-app=\u0026#34;myApp\u0026#34; \u0026gt; … … Then Angular will load this module from JavaScript snippet.\nangular.module(\u0026#34;myApp\u0026#34;, []) Create dependency injector and load dependencies After first step AngularJs will create injector and compiler objects. functionality of compiler object is listed in third step.\nHere injector object will look for dependency of application module. In above example we have not specify any dependency.\nFollowing example illustrate module dependency\nangular.module(\u0026#34;myApp\u0026#34;,[ \u0026#34;ngResource\u0026#34;]) These dependencies are nothing but angular modules. injector load this modules and allow them to be used inside angular application.\nServices can also be injected on fly inside application controller or application services.\n.controller(\u0026#34;myCtrl\u0026#34;, [\u0026#34;$scope\u0026#34;, function($scope){ $scope.title = \u0026#34;Angular Bootstrap Tutorial!\u0026#34; }]) in above example $scope is injected by injector inside controller and we can use it inside controller.\nCompile HTML and create scope for application. Inside last step AngularJs compiles HTML elements using compiler object then creates scope for application and bind rootScope to html element where we have specified ng-app. In above example ng-app is specified inside body tag which means rootScope is attached to body tag and all template logic get applied on this body tag.\nAbove scenario illustrates automatic bootstrapping process. but some time you may require to manually bootstrap AngularJs application where you need to perform some custom JavaScript task before initiating AngularJs application.\nFollowing script snippet shows manual bootstrapping process.\n// document ready event angular.element(document).ready( function() { // bootstrap document with myApp module  angular.bootstrap(document, [\u0026#34;myApp\u0026#34;]) }) As stated earlier bootstrap happens on document ready event therefore you need to configure it first. Then call angular.bootstrap function which will accept two parameters.\nFirst parameter is html element e.g. document, html, body or particular div. this process is equivalent as specifying ng-app directive to HTML element.\nSecond parameter is AngularJs module name. in this case we have give myApp.\nNote that you first need to add module scripting code then initiate bootstrap process otherwise bootstrap will throw error that unable to load given module.\nWith automatic or manual bootstrap, you are ready to create beautiful AngularJs application.\n","permalink":"https://www.zainabed.com/2015/03/angularjs-tutorials-bootstrap.html/","summary":"Introduction Every application starts with bootstrap process which initialize application and wire it other with dependencies and configurations.\nAngularJs is not different from other application. It also starts application with bootstrap process.\nFollowing operation happens inside AngularJs bootstrap process.\n Load application module. Create dependency injector and load dependencies. Compile HTML and create scope for application.  All these steps happens inside angular.js scripting file. therefore we need to include it first.","title":"Angularjs Tutorials Bootstrap"},{"content":"Introduction MongoDB Aggregation Framework groups set of documents together and performs certain operation on this grouped documents and returns results in the form of documents. MongoDB aggregation answer to those query which requires grouping of documents.\nAggregation framework works on three type of model\n Aggregation pipeline Map Reduce Single Purpose Aggregation Operations  Now let see how MongoDB Aggregation Framework works with simple example.\nSuppose you are MongoDB application developer in a respected company and you have been given a MongoDB database that holds information about human population which is distributed according to cities and their states.\nhere is one sample document.\n{ \u0026#34;city\u0026#34; : \u0026#34;ACMAR\u0026#34;, \u0026#34;loc\u0026#34; : [ -86.51557, 33.584132 ], \u0026#34;pop\u0026#34; : 6055, \u0026#34;state\u0026#34; : \u0026#34;AL\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;35004\u0026#34; } for this tutorial collection name is zips.\non first day your manager come and asks you to calculate total population of state DC.\nyour simplest approach to solve above query would be find all documents which have DC as state. then iterate them one by one and add population to a variable.\nhere is the a sample script\nMongoDB script 1 var record = db.zips.find( { \u0026#34;state\u0026#34; : \u0026#34;DC\u0026#34;} ) var sum = 0; record.forEach(function(rec){ sum = sum + rec.pop }) print(\u0026#34;Total population of State DC = \u0026#34; + sum) Total population of State DC = 606900\nThis works fine and given task is done.\nlater, next day your manager comes and tells you to find total population of each states.\nnow this query is little tricky, but you would modify you first MongoDB script and make it is given below.\nMongoDB script 2 var states = db.zips.distinct(\u0026#34;state\u0026#34;) states.forEach(function(state){ var records = db.zips.find({\u0026#34;state\u0026#34; : state}); var sum = 0; records.forEach(function(record){ sum = sum + record.pop; }); print( state + \u0026#34; population: \u0026#34; + sum); }); yes, it will give you expected result. no doubt you are a good MongoDB developer.\nbut you have put extra efforts get result. it does not mean that you are not a good developer, rather you are not aware of MongoDB aggregation framework which produce expected result in one query.\nfollowing is aggregation query\ndb.zips.aggregate([ { \u0026#34;$group\u0026#34; : { \u0026#34;_id\u0026#34; : \u0026#34;$state\u0026#34;, \u0026#34;population\u0026#34; : { \u0026#34;$sum\u0026#34; : \u0026#34;$pop\u0026#34; } }} ]) it will give you same result which in equivalent of second MongoDB script.\nnow let see how it works.\nFirst look out the group clause of aggregate query.\ndb.zips.aggregate([ { \u0026#34;$group\u0026#34; : { \u0026#34;_id\u0026#34; : \u0026#34;$state\u0026#34; } } ]) It will group collections according to state\nas documents are grouped now we can perform calculation on them like summation of population.\ndb.zips.aggregate([ { \u0026#34;$group\u0026#34; : { \u0026#34;_id\u0026#34; : \u0026#34;$state\u0026#34;, \u0026#34;population\u0026#34; : { \u0026#34;$sum\u0026#34; : \u0026#34;$pop\u0026#34; } }} ]) hence you get expected result in one query using MongoDB Aggregation Framework.\n","permalink":"https://www.zainabed.com/2014/11/mongodb-tutorials-aggregation-framework.html/","summary":"Introduction MongoDB Aggregation Framework groups set of documents together and performs certain operation on this grouped documents and returns results in the form of documents. MongoDB aggregation answer to those query which requires grouping of documents.\nAggregation framework works on three type of model\n Aggregation pipeline Map Reduce Single Purpose Aggregation Operations  Now let see how MongoDB Aggregation Framework works with simple example.\nSuppose you are MongoDB application developer in a respected company and you have been given a MongoDB database that holds information about human population which is distributed according to cities and their states.","title":"Mongodb Tutorials Aggregation Framework"},{"content":"Introduction With some examples, this tutorial post will teach the PHP autoloader and namespace concepts.\nWhat is Autoloading in PHP PHP autoload\u0026rsquo;s primary function is to load PHP files into the application context. The import statement is the default method to include PHP file into context.\nHowever, we may avoid the issue by using the PHP autoload capability to autoload essential PHP files, which keeps your code clean and composable.\nWhy do we need auto loading When creating object-oriented applications, many developers create one PHP source file per class declaration. One of the major inconveniences is having to start each script with a huge list of required includes.\nAutloading allows us to include an arbitrary number of PHP files in the application context if they aren\u0026rsquo;t already included by other include statements.\nPHP Autoloading Methods PHP uses two functions; one is the magic method spl_autoload_register and the other is __autoload.\n NOTE: Although __autoload has been DEPRECATED as of PHP 7.2.0, and REMOVED as of PHP 8.0.0, relying on this function is highly discouraged.\n Whenever PHP encounters an instantiation of a class, it triggers the autoloading function by providing it as a parameter.\nYou can also define the path of the class and include it in context within the atoloading method.\nWhat is difference between __autoload and sp_autload_resgister function Because the _autoload method is a magic method, you can only declare it once. As a result, you\u0026rsquo;d just need one logic to incorporate PHP class files.\nspl_autoload_register, on the other hand, takes a function as a parameter, which we can use to create the specific logic for including the PHP file.\nWith the help of spl_autoload_register, we can have multiple implementations of the inclusion of PHP files.\nExample \u0026lt;?php /** * autoload method */ function __autoload($class) { require $class.\u0026#39;.php\u0026#39;; } //spl_autoload_register  /** * autoload method one */ function autoloadOne($class) { require \u0026#34;/dir-one/\u0026#34;.$class.\u0026#34;.php\u0026#34;; } /** * autoload method two */ function autoloadTwo($class) { require \u0026#34;/dir-two/\u0026#34;.$class.\u0026#34;.php\u0026#34;; } //register auto loader spl_autoload_register(\u0026#34;autoloadOne\u0026#34;); spl_autoload_register(\u0026#34;autoloadTwo\u0026#34;); What exactly is namespace In most cases, PHP won\u0026rsquo;t let you have two classes with the same name. However, in version 5.3, the idea of namespace was added, which created class ownership, allowing two classes with the same name but distinct ownership to exist.\nWhat is the importance of namespace in autloading Namespaces were created to solve the problem of name clashes and to allow extra-long class names to be shortened.\nNamespaces are a technique of encapsulating objects in the broadest sense.\nNamespaces in PHP allow you to organise related classes, interfaces, methods, and constants together.\nFor example\n\u0026lt;?php namespace Module\\User\\Controller; namespace Module\\User\\Entity; namespace Module\\User\\Form; namespace Module\\User\\Validator; If we autoload the above class, we will get the whole namespace of that class along with the class name.\nnamespace_autoload.php \u0026lt;?php spl_autoload_register(function ($class_name) { echo \u0026#34;class path = \u0026#34;.$class; die ; } new \\Module\\User\\Controller(); // it will print // class path = Module\\User\\Controller With the help of this information, we can organize classes according to our project directory structure.\nLet\u0026rsquo;s say you have the following project structure.\nproject |__Module |__User |__Controller |__Entity |__Form | |__autoload.php Then you can create PHP classes with a namespace as\n project |__Module |__User |__Controller \\\\ class : IndexController , namespace Module\\User\\Controller |__Entity \\\\ class : User , namespace Module\\User\\Entity |__Form \\\\ class : UserForm , namespace Module\\User\\Form | |__autoload.php file: autoload.php \u0026lt;?php //include namespace  use Module\\User\\Controller\\IndexController; use Module\\User\\Entity\\User; use Module\\User\\Form\\UserForm; /** * Autload project files */ spl_autoload_register(function ($class_name) { echo $class; require $class; } // instantiate classes $controller = new IndexController(); //(it will print) Module\\User\\Controller\\IndexController and load this class  $user = new User(); //(it will print) Module\\User\\Entity\\User and load this class  $userForm = new UserForm(); //(it will print) Module\\User\\Form\\UserForm and load this class As you can see, namespaces aid in the organisation of the project structure and the autoloading of classes.\nWhat is the difference between the following two sets of statements?    Namespace autloading Direct include files     use Module\\User\\Controller\\IndexController; require \u0026ldquo;Module\\User\\Controller\\IndexController\u0026rdquo;;   use Module\\User\\Entity\\User; require \u0026ldquo;Module\\User\\Entity\\User\u0026rdquo;;   use Module\\User\\Form\\UserForm; require \u0026ldquo;Module\\User\\Form\\UserForm\u0026rdquo;;    The main difference is that the require statement accepts the full directory path, whereas with namespace we can set logic to autoload PHP files with different directory structures and minimise the namespace length.\nLet\u0026rsquo;s see the following example. Suppose you have the following directory for your project library files.\nproject | |__vendor | |__lib | |__src | |__components | |__HTTP //Request, Response classes | |__Controller //BaseController classes | |__Form //BaseForm classes ..... many more files You write the following code to use the require statement.\n\u0026lt;?php require \u0026#34;/vendor/lib/src/components/HTTP/Request\u0026#34;; require \u0026#34;/vendor/lib/src/components/HTTP/Response\u0026#34;; require \u0026#34;/vendor/lib/src/components/Controller/BaseController\u0026#34;; require \u0026#34;/vendor/lib/src/components/Form/BaseForm\u0026#34;; We can reduce the above class path and organize the structure much more properly with the help of autoload and namespace as follows.\n\u0026lt;?php define(\u0026#34;LIB_PATH\u0026#34;, \u0026#34;/vendor/lib/src/components\u0026#34;); use HTTP\\Request; use HTTP\\Response; use Controller\\BaseController; use Form\\BaseForm; /** * autoload lib class files */ spl_autoload_register(function ($class_name) { // set class path  $class_path = LIB_PATH.$class; //include class file  echo $class_path; require $class_path; } $request = new Request; // (it will print) /vendor/lib/src/components/HTTP/Request  $controller = new BaseController; // (it will print) /vendor/lib/src/components/Controller/BaseController Conclusion  An autoload helps load all the PHP classes of a PHP project. The combination of autoload and namespace standardises the organisation and loading of PHP projects. Namespace helps organise your PHP classes.  ","permalink":"https://www.zainabed.com/2014/11/php-tutorials-autoload-php-classes.html/","summary":"Introduction With some examples, this tutorial post will teach the PHP autoloader and namespace concepts.\nWhat is Autoloading in PHP PHP autoload\u0026rsquo;s primary function is to load PHP files into the application context. The import statement is the default method to include PHP file into context.\nHowever, we may avoid the issue by using the PHP autoload capability to autoload essential PHP files, which keeps your code clean and composable.","title":"Php Tutorials Autoload Php Classes"},{"content":"Introduction JSON is widely accepted text formatted structured data. JSON stands for \u0026ldquo;JavaScript Object Notation\u0026rdquo;.\nIn general JSON can represent\n Object of database record. Object to represent a list of HTML elements. Result of search query. Response of an Ajax call.  Here you can see JSON is used in many different areas and for many different scenarios. This means it has simple data structure. most of programming languages adopt it and it can flow easily from one connection to another.\nYou can find JSON office definition here JSON Official Site.\nJSON is represented by two structural types, which includes two primitive types.\nStructural types   Array: A sequential list of primitive data types between square brackets   Object: Collection of key, value pair stored inside curly braces { }, where value would be primitive data type\n  Primitive types There are two primitive types key and value. \u0026ldquo;key\u0026rdquo; should be string and \u0026ldquo;value (data type)\u0026rdquo; could be anything like integer, string , Boolean , empty or null.\nLets see some example of JSON objects.\nArray [ \u0026#34;apple\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;blackberry\u0026#34;, \u0026#34;grape\u0026#34; ] Object { \u0026#34;username\u0026#34;: \u0026#34;zainabed\u0026#34;, \u0026#34;first_name\u0026#34;: \u0026#34;Zainul\u0026#34;, \u0026#34;country\u0026#34;: \u0026#34;India\u0026#34; } Mix Object { \u0026#34;username\u0026#34;: \u0026#34;zainabed\u0026#34;, \u0026#34;first_name\u0026#34;: \u0026#34;Zainul\u0026#34;, \u0026#34;country\u0026#34;: \u0026#34;India\u0026#34;, \u0026#34;hobby\u0026#34;: [ \u0026#34;reading\u0026#34;, \u0026#34;programming\u0026#34;, \u0026#34;sports\u0026#34; ] } JSON is widely accepted and used because\n  It is lightweight, that is why it is possible to transfer large set of data without exhausting internet bandwidth.\n  It is language independent, which means most of the programing languages have mechanism to accept or generate JSON objects, it doesn’t need extra functionality to make JSON objects compatible with other languages.\n  JSON can be as primary object for database system. it is used to store and read or perform CRUD operation on JSON which can be stored as documents. MongoDB is popular database system which based on JSON documents.\n  JSON can have Embedded documents as well, it helps to avoid expensive join operations on related documents. here rather using joins, one JSON documents can be embedded inside another.\n  JSON object can be used to represent HTML entities like list of user, tables or image gallery. AngularJs is most powerful tool to transform JSON to HTML.\n  JSON can also represent search result. search result could include search count, search title and description list , etc. all this can be included in a JSON object. Elasticsearch represent its search result in JSON object. as it is JSON object it can be used in any programming languages as result.\n  JSON play important role in drawing of charts. charts requires data set to create a particular chart and JSON object is perfect data model for it. D3 charts are always use JSON objects.\n  Frequently Asked Questions 1: Can JSON starts with Array? Answer: Yes, JSON can start with Array or Object, there is no such restriction.\n2: What is the correct JSON content type for HTTP response? Answer: Correct content type for JSON is application/json\n3: Safely turning a JSON string into an object inside a JavaScript? Answer: Following two function call will turn string to JSON object\njQuery.parseJSON( jsonString ); //Jquery  JSON.parse(jsonString); //plain JavaScript ","permalink":"https://www.zainabed.com/2014/10/json-tutorials-getting-started.html/","summary":"Introduction JSON is widely accepted text formatted structured data. JSON stands for \u0026ldquo;JavaScript Object Notation\u0026rdquo;.\nIn general JSON can represent\n Object of database record. Object to represent a list of HTML elements. Result of search query. Response of an Ajax call.  Here you can see JSON is used in many different areas and for many different scenarios. This means it has simple data structure. most of programming languages adopt it and it can flow easily from one connection to another.","title":"Json Tutorials Getting Started"},{"content":"Introduction In this tutorial, we will look at how to install Doctrine2 in your PHP project.\nThis post will make use of Doctrine2\u0026rsquo;s Composer tool.\nInstallation First, create a directory for your project.\nmkdir zainabed cd zainabed Now, create a composer.json file.\nvi composer.json Then, add the following repository information to it.\n{ \u0026#34;require\u0026#34;: { \u0026#34;doctrine/orm\u0026#34;: \u0026#34;*\u0026#34; } } You are now ready to use Composer to install Doctrine, but first you must install Composer on your machine.\ncurl -sS https://getcomposer.org/installer | php To install Doctrine2, run the following command.\nphp composer.phar install  Note: Composer generates a \u0026ldquo;autoload.php\u0026rdquo; file to help in the autoloading of all PHP classes in the Doctrine2 ORM project.\n Configuration First, create a configuration file, configuration.php for Doctrine2 and include autoload.php inside it.\n\u0026lt;?php // configuration.php  // Include Composer Autoload require_once \u0026#34;vendor/autoload.php\u0026#34;; Then, create the database configuration details, like database name, username and password. // database configuration  $databaseParams = array( \u0026#39;driver\u0026#39; =\u0026gt; \u0026#39;pdo_mysql\u0026#39;, \u0026#39;user\u0026#39; =\u0026gt; \u0026#39;root\u0026#39;, \u0026#39;password\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;dbname\u0026#39; =\u0026gt; \u0026#39;zainabed\u0026#39;, ); Now, specify the entity path where you want all ORM entities to be stored.\n//entity path $entityPath = array(\u0026#34;src/Entity\u0026#34;); Create an Entity Manager ORM\u0026rsquo;s fundamental source is the Entity Manager, which manages interactions between entities and databases.\n//annotation configuration $config = Setup::createAnnotationMetadataConfiguration($entityPath, false); //entity manager object $entityManager = EntityManager::create($databaseParams, $config); Finally, you are ready to use Doctrine2 within your PHP project.\nThe following is a complete configuration example that includes XML and YAML configuration.\n\u0026lt;?php // configuration.php  // Include Composer Autoload require_once \u0026#34;vendor/autoload.php\u0026#34;; use Doctrine\\ORM\\Tools\\Setup; use Doctrine\\ORM\\EntityManager; // database configuration $databaseParams = array( \u0026#39;driver\u0026#39; =\u0026gt; \u0026#39;pdo_mysql\u0026#39;, \u0026#39;user\u0026#39; =\u0026gt; \u0026#39;root\u0026#39;, \u0026#39;password\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;dbname\u0026#39; =\u0026gt; \u0026#39;zainabed\u0026#39;, ); //entity path $entityPath = array(\u0026#34;src/Entity\u0026#34;); //annotation configuration $config = Setup::createAnnotationMetadataConfiguration($entityPath, false); //entity manager object $entityManager = EntityManager::create($databaseParams, $config); //xml configuration //$xmlEntituPath = array(\u0026#34;/path/to/xml-mappings\u0026#34;); //$config = Setup::createXMLMetadataConfiguration($xmlEntituPath, false); //$entityManager = EntityManager::create($databaseParams, $config);  //yml configuration //$ymlEntityPath = array(\u0026#34;/path/to/yml-mappings\u0026#34;); //$config = Setup::createYAMLMetadataConfiguration($ymlEntityPath, false); //$entityManager = EntityManager::create($databaseParams, $config); Doctrine 2 is now configured and ready to use.\n","permalink":"https://www.zainabed.com/2014/10/doctrine2-installation-configuration.html/","summary":"Introduction In this tutorial, we will look at how to install Doctrine2 in your PHP project.\nThis post will make use of Doctrine2\u0026rsquo;s Composer tool.\nInstallation First, create a directory for your project.\nmkdir zainabed cd zainabed Now, create a composer.json file.\nvi composer.json Then, add the following repository information to it.\n{ \u0026#34;require\u0026#34;: { \u0026#34;doctrine/orm\u0026#34;: \u0026#34;*\u0026#34; } } You are now ready to use Composer to install Doctrine, but first you must install Composer on your machine.","title":"Doctrine2 Installation Configuration"},{"content":"Introdcution In this tutorial, we\u0026rsquo;ll look at how to install Twig within your PHP project and thereafter configure it so that we can create and use a Twig template inside our PHP web application.\nLater on, we\u0026rsquo;ll see a simple Twig template example that displays a Welcome to Twig template message.\nLet\u0026rsquo;s take it one step at a time.\nInstallation The Twig template can be installed using Composer, Git, or PEAR.\nIn this tutorial, we will use Composer to install Twig.\nTo do so, we\u0026rsquo;ll need to make a \u0026ldquo;composer.json\u0026rdquo; file.\n{ \u0026#34;require\u0026#34;: { \u0026#34;twig/twig\u0026#34;: \u0026#34;1.*\u0026#34; } } From the console, run the following command.\nphp composer.phar install This command will install Twig library.\nConfiguration To use the Twig template, we should first configure it. To achieve this, we will write an index.php file which will configure the Twig autoloader and generate the Twig environment.\nWe will render the Twig template using this Twig environment.\n\u0026lt;?php include __DIR__ . \u0026#34;/vendor/twig/twig/lib/Twig/Autoloader.php\u0026#34;; //register autoloader Twig_Autoloader::register(); //loader for template files $loader = new Twig_Loader_Filesystem(\u0026#39;templates\u0026#39;); //twig instance $twig = new Twig_Environment($loader, array(\u0026#39;cache\u0026#39; =\u0026gt; \u0026#39;cache\u0026#39;)); //load template file $template = $twig-\u0026gt;loadTemplate(\u0026#39;index.html\u0026#39;); //render a template echo $template-\u0026gt;render(array(\u0026#39;title\u0026#39; =\u0026gt; \u0026#39;Welcome to Twig template\u0026#39;)); Next, we will create a \u0026ldquo;template.html\u0026rdquo; file inside template folder.\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;{{ title }}\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; As a result, you will get the following output when you run the index.php file on localhost.\nThat\u0026rsquo;s it. We are done with the Twig installation and configuration process.\nSource Code Download source code from this Github.\n","permalink":"https://www.zainabed.com/2014/10/twig-tutorials-install-and-configure.html/","summary":"Introdcution In this tutorial, we\u0026rsquo;ll look at how to install Twig within your PHP project and thereafter configure it so that we can create and use a Twig template inside our PHP web application.\nLater on, we\u0026rsquo;ll see a simple Twig template example that displays a Welcome to Twig template message.\nLet\u0026rsquo;s take it one step at a time.\nInstallation The Twig template can be installed using Composer, Git, or PEAR.","title":"Twig Tutorials Install and Configure"},{"content":"Introduction This post will show you how to generate SSH private and public keys step by step, as well as how to add public keys to your GitHub and Bitbucket accounts.\nBut first, why do we require this SSH public key If you want to do any work on a secure GIT repository, such as cloning or pushing your latest changes, you will need to provide your credentials to help GIT authenticate you and approve those operations, whether you are working in a team or as an individual.\nHowever, each time you operate, you are prompted to enter your username and password.\nIt appears simple at first, but it quickly becomes a source of frustration.\nTo overcome the above problem, we can use the SSH protocol. SSH connections allow us to authenticate using public and private keys that we generate only once. after that, we don\u0026rsquo;t need to authenticate because SSH will do so on our behalf.\nBut how does it work SSH authenticates you using an identity, and this identity is made up of a combination of private and public keys.\nA private key is stored on your local machine, while a public key is stored on your GitHub or Bitbucket account. When you perform any operation on a Git repository that requires your authentication, SSH combines these two keys.\nTo use SSH, you must first install it. Please follow the steps given in the following link. http://www.openssh.com\nGenerate private-public keys Follow the steps below to generate a private and public key. Open a terminal and enter the following command.\nssh-keygen It will request the location of key files. To select the default location, press Enter.\nIt will then request a passphrase (password). You can omit it, but it is preferable to include one.\nAfter that, it will prompt you to reenter your password for confirmation.\nAfter that, keys will be generated and saved in the specified location.\nHere\u0026rsquo;s an example of the ssh-keygen operation\u0026rsquo;s output.\nNext, add your key to the ssh-agent.\nssh-add ~/.ssh/id_rsa Later, you need to add the public key to your GitHub and Bitbucket accounts. To do so, we need to get content of the public key. This resides inside ~/.ssh path.\ncat ~/.ssh/id_rsa.pub Copy this key and go to GitHub or Bitbucket to add it to your account.\nGitHub Log in to your GitHub account in a browser.\n Select the setting icon from the menu bar\u0026rsquo;s top right corner. Then select SSH keys from the left side panel. Now add the new public key by selecting the Add SSH key button. It will open a panel to enter a public key. Add a label for the public key and then add the copied public key inside the key area. Now finish this process by clicking the Add key button.  That’s it. The configuration for GitHub is done.\nBitbucket Open a browser and log into your Bitbucket account.\n Select Avatar-\u0026gt;Manage Account from the application menu. Under Security section Click SSH keys. Then click Add key button. It will prompt a dialog to add public key. Add label for public key and then add copied public key inside key area. Now finish this process by clicking Add key button.  This will complete the configuration for Bitbucket.\nConclusion If you want your repository to run smoothly, use SSH with public and private key configuration.\n","permalink":"https://www.zainabed.com/2014/10/ssh-public-key-for-github-and-bitbucket.html/","summary":"Introduction This post will show you how to generate SSH private and public keys step by step, as well as how to add public keys to your GitHub and Bitbucket accounts.\nBut first, why do we require this SSH public key If you want to do any work on a secure GIT repository, such as cloning or pushing your latest changes, you will need to provide your credentials to help GIT authenticate you and approve those operations, whether you are working in a team or as an individual.","title":"Ssh Public Key for Github and Bitbucket"},{"content":"Introduction Symfony EventDispatcher is object which interacts with different set of objects when certain event happens.\nTo illustrate Event Dispatcher definition let’s consider the online shopping website example.\nsuppose you want to purchase a mobile from online shopping website , but unfortunately that mobile is out of stock.\nThen you subscribe into online shopping website for this mobile availability.\nWhen mobile comes in stock, online shopping website notifies you about mobile phone’s availability via email.\nIn above scenario\n you are the Event Listener / Event Subscriber mobile availability is Event online shopping website is Event Dispatcher.  Symfony EventDispatcher works in same manner.for example, whenever there is HTTP request, Kernel creates a request object and it dispatches an event kernel.request.\nWhoever subscribes to kernel.request event gets notified.\nSo here you might be having few questions in my mind.\nWhat is Event Event object describe what event is and add some additional information so that its listener or subscriber can get enough information about event.\nWhat is EventDispatcher EventDispatcher is central object which dispatches the event to all its listener or subscriber. EventDispatcher maintains the list of all listeners of a particular Event.\nuse Symfony\\Component\\EventDispatcher\\EventDispatcher; $dispatcher =new EventDispatcher(); What is Event Listener Listener is a object which performs a task whenever a associated event happens. But first we need to attach listener to Event Dispatcher for a particular event.\n$listener=new MobileAvailabilityListener(); $dispatcher-\u0026gt;addListener(\u0026#39;store.mobile.available\u0026#39;,array($listener,\u0026#39;sendEmailToUsers\u0026#39;)); Considering Online Shopping Store example let’s create a custom event and dispatch this event.\nHere we want to create mobile availability event which get dispatched whenever mobile is available.\nFirst we create static event class which holds event name and its instance information\nStatic Event Class\nfinal class MobileEvents { /** * The store.mobile.available event is thrown each time when mobile * is available in store * * The event listener receives an * Acme\\StoreBundle\\Event\\MobileAvailableEvent instance. * * @var string */ const MOBILE_AVAILABLE = \u0026#39;store.mobile.available\u0026#39;; } Later, create actual event object.\nSymfony uses Symfony\\Component\\EventDispatcher\\Event class.\nThis class wont give us enough information about mobile availability therefor we need to subclass it and add additional information.\nnamespace Acme\\StoreBundle\\Event; use Symfony\\Component\\EventDispatcher\\Event; use Acme\\StoreBundle\\Mobile; class MobileAvailableEvent { protected $mobile; public function__construct(Mobile $mobile) { $this-\u0026gt;mobile=$mobile; } public function getMobile() { return $this-\u0026gt;mobile; } } Later, create event listener, which sends emails to user regarding availability of the mobile phone.\nuse Acme\\StoreBundle\\Event\\MobileAvailableEvent; class MobileAvailabilityListener { // ...  public function sendEmailToUsers(MobileAvailableEvent $event) { // ... send email to users  } } Now all is set, let’s attach this listener to the dispatcher. And dispatch the event.\nuse Symfony\\Component\\EventDispatcher\\EventDispatcher; use Acme\\StoreBundle\\Event\\MobileAvailableEvent; use Acme\\StoreBundle\\Event\\MobileAvailabilityListener; use Acme\\StoreBundle\\Entity\\Mobile; $dispatcher = new EventDispatcher(); // attach listener $listener = new MobileAvailabilityListener(); $dispatcher-\u0026gt;addListener(MobileEvents::MOBILE_AVAILABLE, array($listener, \u0026#39;sendEmailToUsers\u0026#39;)); //if mobile is available then dispatch the event $mobile = new Mobile(); $event = new MobileAvailableEvent($mobile); $dispatcher-\u0026gt;dispatch(MobileEvents::MOBILE_AVAILABLE, $event); Conclusion This is a every basic example, you can create event for user registration process and can send confirmation email via event listener or can do many things using Symfony Event Dispatcher.\n","permalink":"https://www.zainabed.com/2014/10/symfony-tutorials-event-dispatcher.html/","summary":"Introduction Symfony EventDispatcher is object which interacts with different set of objects when certain event happens.\nTo illustrate Event Dispatcher definition let’s consider the online shopping website example.\nsuppose you want to purchase a mobile from online shopping website , but unfortunately that mobile is out of stock.\nThen you subscribe into online shopping website for this mobile availability.\nWhen mobile comes in stock, online shopping website notifies you about mobile phone’s availability via email.","title":"Symfony Tutorials Event Dispatcher"},{"content":"Introduction Custom Module development in Drupal 8 is very simple. It may looks very difficult for developer who has Drupal 7 experience or nothing at all.\nThis tutorial will show easy steps and helps you to create custom module within few minutes.\n Note: Content or example of this tutorial may change according to Drupal 8 version and its release.\n This tutorial is divided into three small sections.\nIn first section of this tutorial we will see what directory structure we need to create for a custom module.\nIn second section we will see what type files we need to create.\nAnd in last section we will see what code we need to write in those files and configure them in Drupal 8.\nDirectory Structure All custom module in Drupal 8 reside under “module” directory of Drupal 8 project.\nTo create a custom module we will create a new directory named “document” under custom folder.\nFollowing is directory structure.\nConfiguration files Second thing that we need to create is YAML files which represent custom module configurations.\nFollowings are files that you need to create.\n {module name}.info.yml i.e document.info.yml {module name}.module i.e document.module  only document.info.yml file is enough for configuring of document module.\nFollowing is directory structure after including these files\nWriting Configuration Settings Add following code inside document.info.yml\nname: Document description: Document Module package: Document core: 8.x version: 1.0 type: module Above configuration settings are very descriptive except only one parameter which is type.\nAs we are creating custom module therefore type parameter must be typed as module.\nNow your module is ready to enable and use.\nGo to Drupal Admin page and enable document module from\nAdmin-\u0026gt;Extend link\nNow search document module in search list\nThen select check box before document module name and click Save Configuration button.\nThat’s it, custom document is now ready to use\nNext tutorial will help you create custom controller for this custom module.\n","permalink":"https://www.zainabed.com/2014/09/drupal-8-tutorials-custom-module.html/","summary":"Introduction Custom Module development in Drupal 8 is very simple. It may looks very difficult for developer who has Drupal 7 experience or nothing at all.\nThis tutorial will show easy steps and helps you to create custom module within few minutes.\n Note: Content or example of this tutorial may change according to Drupal 8 version and its release.\n This tutorial is divided into three small sections.\nIn first section of this tutorial we will see what directory structure we need to create for a custom module.","title":"Drupal 8 Tutorials Custom Module"},{"content":"Introduction Following is simple JAX-RS tutorial, which sends “Hello World” text as response string using JAX-RS API and Jersey implementation. Technologies and Tools used in this article:\n JDK Eclipse Tomcat Maven Jersey 1.8  Create Maven Web Project Create a Maven web project and name it \u0026ldquo;helloworld\u0026rdquo; .\n File -\u0026gt; New -\u0026gt; Other -\u0026gt; Maven Project -\u0026gt; Next Select maven-archetype-webapp Select Next Type Group Id, Artifact Id and Package name And select Finish  Add Project Dependencies Add Jersey repository using Maven. Use Maven URL to get appropriate repository.\nNow update pom.xml file by adding following dependency.\nFile : pom.xml \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.sun.jersey\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jersey-server\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Create REST Service Now it is time to create a class which serves as REST service. Create class named RestService and a public method getMessage\npackage com.zain.restapi; import javax.ws.rs.core.Response; import javax.ws.rs.GET; import javax.ws.rs.Path; @Path(\u0026#34;/message\u0026#34;) public class RestService { @GET public Response getMessage() { String message = \u0026#34;Hello World!\u0026#34;; return Response.status(200).entity(message).type(\u0026#34;text/plain\u0026#34;).build(); } }  Note: @Path annotation act as routing which map incoming URI to appropriate Class Update web.xml for Jersey configuration In web.xml, add servlet with class com.sun.jersey.spi.container.servlet.ServletContainer\n File : web.xml \u0026lt;web-app version=\u0026#34;2.4\u0026#34; xmlns=\u0026#34;http://java.sun.com/xml/ns/j2ee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://java.sun.com/xml/ns/j2ee http://java.sun.com/xml/ns/j2ee/web-app_2_4.xsd\u0026#34;\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;jersey-serlvet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt; com.sun.jersey.spi.container.servlet.ServletContainer \u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;com.sun.jersey.config.property.packages\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;com.zain.restapi\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;jersey-serlvet\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/rest/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; Directory Structure Final project directory structure\nDemo To execute this application you need to type following URL\nhttp://localhost:8080/{project name}/{jersey servlet name}/{@path param value} here is actual URL for this tutorial.\nhttp://localhost:8080/helloworld/rest/message Source Code Download source code from this Github\nReferences  Jersey Official Website Jersey hello world example RESTful Web Services  ","permalink":"https://www.zainabed.com/2014/07/jax-rs-tutorilas-hello-world-example.html/","summary":"Introduction Following is simple JAX-RS tutorial, which sends “Hello World” text as response string using JAX-RS API and Jersey implementation. Technologies and Tools used in this article:\n JDK Eclipse Tomcat Maven Jersey 1.8  Create Maven Web Project Create a Maven web project and name it \u0026ldquo;helloworld\u0026rdquo; .\n File -\u0026gt; New -\u0026gt; Other -\u0026gt; Maven Project -\u0026gt; Next Select maven-archetype-webapp Select Next Type Group Id, Artifact Id and Package name And select Finish  Add Project Dependencies Add Jersey repository using Maven.","title":"Jax Rs Tutorilas Hello World Example"},{"content":"Introduction Sass (Syntactically Awesome Stylesheets) is scripting language which produces Cascading Style Sheets (CSS).\nSass is compatible with all CSS version and has assorted features. It is open source and developed in Ruby.\nWhat does Sass do In simple terms by using Sass and its features we can create robust and large Style sheet with less effort and in less time.\nHow to Install Sass Sass requires Ruby, so if you are using Windows System then you need to install Ruby first. Here is URL of Ruby Installer.\nOtherwise if you use Mac or Linux System then you don’t need Ruby, it is pre-configured.\nUse following commands to install Sass\nsudo gem install sass use following command to verify Sass is installed properly or not.\nsass -v To begin with Sass, create Sass “main.scss” file and CSS “main.css” file\nThen run following command\nsass --watch main.scss:main.css It will update main.css file whenever you do changes and save Sass file.\nSass Script   Variable   Sass variable is use to store information at one place and can be used at various place through out the whole Style Sheet.\n$base-font: Arial, sans-serif; $base-color: #555; h1{ font: 100% $base-font; color: $base-color; }  Nesting   Nesting is associated to CSS control structure define under enclosing brackets.\nsection { div { padding: 10px; position: relative; } p { margin: 10px; } } Which produce following CSS style.\nsection div { padding: 10px; position: relative; }\nsection p { margin: 10px; }\n Mixins   Mixins allow you to group set of CSS code and reuse it by including whole set of those code inside other CSS selectors. it looks like function with parameter.\n@mixin border-radius($box-sizing) { -webkit-box-sizing: $box-sizing; -moz-box-sizing: $box-sizing; -ms-box-sizing: $box-sizing; box-sizing: $box-sizing; } .container{ @include border-radius(border-box); }  Extends   Extends is like inheritance where you can share CSS properties from one selector to another.\n.button { padding: 10px; height :30px; line-height: 30px; } .red-button{ @extend .button; background: red; } .green-button { @extend .button; background: green; }  Partials / Import   Partials are Sass files starts with underscore in beginning of their names. underscore indicate Sass that it is a Partial and Sass does not convert it into CSS file. you rather include this Partial in other Sass files using @import keyword. Partials create structure of Style files and can be reuse in many other files.\n/* _base.scss */ body { font-family : Arial, Verdana; margin: 0 10px; } /* home.scss */ @import \u0026#39;base\u0026#39;; p { background-color: #eee; }  Operators   Sass provides +, -, *, % and / operators to perform mathematical operations.\n$width: 900px; .md-1 { width: $width; } .md-2{ width: $width/2; } .md-4{ width: $width/4; } References  Sass Official Site Sass Wiki  ","permalink":"https://www.zainabed.com/2014/07/sass-tutorials.html/","summary":"Introduction Sass (Syntactically Awesome Stylesheets) is scripting language which produces Cascading Style Sheets (CSS).\nSass is compatible with all CSS version and has assorted features. It is open source and developed in Ruby.\nWhat does Sass do In simple terms by using Sass and its features we can create robust and large Style sheet with less effort and in less time.\nHow to Install Sass Sass requires Ruby, so if you are using Windows System then you need to install Ruby first.","title":"Sass Tutorials"},{"content":"Introdcution JAX-RS is API specification for RESTful web services using Java. RESTful web services is implementation of REST (Representational State Transfer) which is architectural design for distributed system or in general we can say JAX-RS is a set of APIs to develop REST service.\nThis is a brief introduction about REST and JAX-RS. You can find more information on REST on Wiki and JAX-RS Official Site.\nWhat is REST  Representational state transfer is an abstraction of the architecture of the World Wide Web. More precisely, REST is an architectural style consisting of a coordinated set of architectural constraints (source Wikipedia)  As JAX-RS is only a specification, we need to use it\u0026rsquo;s implemented library to create RESTful web service.\nFollowing are such list of libraries\n Apache CXF, an open source Web service framework. Jersey, the reference implementation from Sun (now Oracle). RESTeasy, JBoss\u0026rsquo;s implementation. Restlet, created by Jerome Louvel, a pioneer in REST frameworks Apache Wink, Apache Software Foundation Incubator project, the server module implements JAX-RS.  For this JAX-RS tutorials set we will use Jersey library and Maven for dependency management.\nQuick Start Following are some start-up JAX-RS examples.\n  Simple Hello World Example\nsimple JAX-RS tutorial, which sends “Hello World” text as response string using JAX-RS API and Jersey implementation.\n  JSON Response Example\n  References  Jersey Official Website Jersey hello world example RESTful Web Services  ","permalink":"https://www.zainabed.com/2014/07/jax-rs-tutorial-rest-api-using-java.html/","summary":"Introdcution JAX-RS is API specification for RESTful web services using Java. RESTful web services is implementation of REST (Representational State Transfer) which is architectural design for distributed system or in general we can say JAX-RS is a set of APIs to develop REST service.\nThis is a brief introduction about REST and JAX-RS. You can find more information on REST on Wiki and JAX-RS Official Site.\nWhat is REST  Representational state transfer is an abstraction of the architecture of the World Wide Web.","title":"Jax Rs Tutorial Rest Api Using Java"},{"content":"Introduction This article will show you how to use Java to perform CRUD operations on MongoDB records.\nIf you\u0026rsquo;re new to MongoDB, we recommend starting with the Getting Started With MongoDB tutorial.\nTo begin, we\u0026rsquo;ll establish a Person and Person Images table (a collection in MongoDB) to make CRUD operations in MongoDB easier.\nDefine Data Structure The following is the data structure of the Person and Person Images table (collection in MongoDB).\nPerson    id Int (primary)     username String   first_name String   last_name String   email String   description String   birthdate Date   country String   state String   city String   lat String   lang String   job String    Person Images    id Int(Primary)     person_id Int   image_path String   width Int   height Int   aspect_ration Double   like Int   dislike Int    We\u0026rsquo;ll use these data structures and associated records to develop interactive image galleries and search engine systems in later tutorial posts.\nCreate maven project Now, create a new project in eclipse and select\n File -\u0026gt; New -\u0026gt; Other -\u0026gt; Maven Project -\u0026gt; Next Select maven-archetype-quickstart Select Next Type Group Id, Artifact Id and Package name And select Finish  This will create Maven based Java project .\n Note: What is Maven\u0026rsquo;s purpose? Although Maven is not required, it allows us to avoid manually installing external libraries such as the MongoDB Java library. Maven aids in the reduction of time and effort by adding the library and its version.\n Add following snippet inside pom.xml file inside dependencies tag.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mongodb\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mongo-java-driver\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.12.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  Note: You can find this dependency (java library and drivers) and its version for Maven on http://mvnrepository.com\n MongoDB connection MongoClient mongoClient= new MongoClient(\u0026#34;localhost\u0026#34;,27017); /** Other methods to create client MongoClient mongoClient= new MongoClient(); MongoClient mongoClient= new MongoClient(\u0026#34;localhost\u0026#34;); */ The MongoDb client can be obtained in three ways. One without any contractor parameters, or others with a server address or port number.\nTo create database use following snippet.\nDB zainabedDB = mongoClient.getDB(\u0026#34;zainabed\u0026#34;); If “zainabed” database is not present in MongoDB then it get created.\nPrint All Available Database List\u0026lt;String\u0026gt; databaseNames = mongoClient.getDatabaseNames(); for (String dbName : databaseNames) { System.out.println(\u0026#34;Database : \u0026#34; + dbName); } It will print all database names presents in MongoDB.\nSelect or Create Collection The collection acts as a table (RDBMS) and in this tutorial it will be Person and Person Images.\nUse the following code to create a collection.\nDBCollection personCollection = zainabedDB.getCollection(\u0026#34;person\u0026#34;); The code above will either choose the collection or create it if it does not already exist.\nUse the following code to get a list of all available collection names for a given database.\nSet\u0026lt;String\u0026gt; collectionNames = zainabedDB.getCollectionNames(); for(String collection : collectionNames){ System.out.println(\u0026#34;collection : \u0026#34; + collection); } Create Record (Person) BasicDBObject is used to create a row object which get inserted into collection.\nFollowing code inserts a row into Person collection.\nBasicDBObject person = new BasicDBObject() .append(\u0026#34;username\u0026#34;,\u0026#34;zainabed\u0026#34;) .append(\u0026#34;first_name\u0026#34;,\u0026#34;Zainul\u0026#34;) .append(\u0026#34;last_name\u0026#34;,\u0026#34;Shaikh\u0026#34;) .append(\u0026#34;email\u0026#34;,\u0026#34;xyz@gmail.com\u0026#34;) .append(\u0026#34;description\u0026#34;,\u0026#34;Software Developer\u0026#34;) .append(\u0026#34;birthdate\u0026#34;,new SimpleDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;).parse(\u0026#34;1985-03-13\u0026#34;)) .append(\u0026#34;country\u0026#34;,\u0026#34;india\u0026#34;) .append(\u0026#34;state\u0026#34;,\u0026#34;maharashtra\u0026#34;) .append(\u0026#34;city\u0026#34;,\u0026#34;pune\u0026#34;) .append(\u0026#34;job\u0026#34;,\u0026#34;Software Developer\u0026#34;) .append(\u0026#34;lat\u0026#34;,\u0026#34;18.526895\u0026#34;) .append(\u0026#34;long\u0026#34;,\u0026#34;73.856101\u0026#34;); personCollection.save(person); Now, we will insert a record inside Person Image collection.\nTo do so, first we need to select or create Person Image collection.\nDBCollection personImagesCollection = zainabedDB.getCollection(\u0026#34;person_images\u0026#34;); Later, we will create person image BasicDBobject as,\nBasicDBObject personImage = new BasicDBObject() .append(\u0026#34;person_id\u0026#34;, person.get(\u0026#34;_id\u0026#34;)) .append(\u0026#34;image_path\u0026#34;, \u0026#34;/23gfd945j4k4.png\u0026#34;) .append(\u0026#34;width\u0026#34;, 400) .append(\u0026#34;height\u0026#34;, 400) .append(\u0026#34;aspect_ration\u0026#34;, 1.0) .append(\u0026#34;like\u0026#34;, 1000) .append(\u0026#34;dislike\u0026#34;, 45); Here we have used “_id” field of Person object to create association.\nNow this object is ready for insert into db.\npersonImagesCollection.save(personImage); Read MongoDB Records MongoDB read operation is very simple, we will see possible read operations such as\n Find single record Find all records using cursor object Find records using condition  Find Single Record: To find single record from given collection we will use find() method of collection object.\nDBObject result = personCollection.findOne(); System.out.println(result); It will print single result object.\nFind All Records Using Cursor Object To fetch all person records we will use find() method of collection and it will provide a cursor to iterate through all records.\nDBCursor personCursor = personCollection.find(); while(personCursor.hasNext()){ System.out.println(personCursor.next()); } Find records using condition object We will use condition object (BasicDBObject) to filter out desired results.\nBasicDBObject coditionObject = new BasicDBObject(\u0026#34;job\u0026#34;,\u0026#34;Software Developer\u0026#34;); result = personCollection.findOne(coditionObject); System.out.println(result); To filter that column, we specify a condition object with a field and a value.\nUpdate MongoDB Records The update method of a collection object is used to update a record.\nTwo objects are required for the update method, one to filter out the targeted row and the other to alter the value of a specific column.\nBasicDBObject queryObject = new BasicDBObject(\u0026#34;username\u0026#34;,\u0026#34;zainabed\u0026#34;); BasicDBObject updateObject = new BasicDBObject(\u0026#34;$set\u0026#34;, new BasicDBObject(\u0026#34;email\u0026#34;,\u0026#34;abc@gmail.com\u0026#34;); personCollection.update(queryObject, updateObject);  Note: Here we used the \u0026ldquo;$set\u0026rdquo; option to update a record, otherwise it will replace the entire row with the given update column values.\n Delete MongoDB Records The remove () method of collection is used to remove a record from a collection.\nTo filter records that need to be deleted, we\u0026rsquo;ll need a query object.\nqueryObject = new BasicDBObject(\u0026#34;email\u0026#34;,\u0026#34;abc@gmail.com\u0026#34;); personCollection.remove(queryObject); Conclusion This post provided a quick overview of how to use MongoDB from Java.\nAll of these samples and code snippets can be found on the Github page.\n","permalink":"https://www.zainabed.com/2014/06/mongodb-crud-operations-using-java.html/","summary":"Introduction This article will show you how to use Java to perform CRUD operations on MongoDB records.\nIf you\u0026rsquo;re new to MongoDB, we recommend starting with the Getting Started With MongoDB tutorial.\nTo begin, we\u0026rsquo;ll establish a Person and Person Images table (a collection in MongoDB) to make CRUD operations in MongoDB easier.\nDefine Data Structure The following is the data structure of the Person and Person Images table (collection in MongoDB).","title":"Mongodb Crud Operations Using Java"},{"content":"Introduction Elasticsearch is open source search system based of Apache Lucene. this is a brief introduction, you can find more information on Elasticsearch Official Site or Wiki.\nWhat are features of Elasticsearch Here are list of features of Elasticsearch.\n Real Time Search and Analytic. Distributed Data (Scales Horizontally) Based on Apache Lucene High Availability Full Text Search JSON Based Documents RESTful API Multi Facets Geo Location Search Open Source  How to install ElasticSearch Download the latest version from Elastic.\nThen unzip it or use following command in console to download Elasticsearch.\ncurl -L -O http://download.elasticsearch.org/PATH/TO/LATEST/$VERSION.zip unzip elasticsearch-$VERSION.zip cd elasticsearch-$VERSION Now move to unzip folder and run following command\n{elasticsearch unzip folder path}/bin/elasticsearch\nIt will start Elasticsearch.\nHow to use ElasticSearch To interactive with data using Elasticsearch we will use head plugin of Elasticsearch.\nTo install head plugin in your system run following command.\n{elasticsearch unzip folder path}/bin/plugin --install mobz/elasticsearch-head After successful installation open your favorite browser and type following URL to use head plugin.\nhttp://localhost:9200/_plugin/head It will open head plugin user interface, now we can manipulate Elasticsearch records.\nTo start with data manipulation, first we need to create Index and Type.\nIndex acts as Database and Type as Table, therefore we can have multiple Type inside single Index.\nFirst create new index, to create new index click button New Index from homepage of head plugin.\nThen type name of index (for this blog we type \u0026ldquo;database\u0026rdquo; as Index and use Type as \u0026ldquo;Table\u0026rdquo;) and click Ok.\nIt will create new index on Elasticsearch.\nHow to perform CRUD operation on Elasticsearch To perform CRUD operation on Elasticsearch select Any Request Tab It will open user interface as shown below\nThere are several section defined in above image. lets see them one by one\n Index: Index on which you want to perform action, it is located just after localhost:9200/ Type: Type within selected Index, it will come after Index value. Action: which type of action you want to perform like search, mapping, etc. Action Method: it is REST API action methods like POST, GET, PUT, DELETE.  Following is record or document structure that we are going to create.\n{ name : String, description: String, profile_image : String, birthdate : Date, address: String } Create Mapping First new need to define structure of data, by default it would be string for all fields but we can set different data type as date, geo point, etc.\nTo define mapping, select Index and Type, then type _mapping in Action area to perform mapping related tasks, then select Action Method as POST and type following mapping structure and click on Request button.\n{ \u0026#34;table\u0026#34;: { \u0026#34;properties\u0026#34;:{ \u0026#34;name\u0026#34;: {\u0026#34;type\u0026#34; : \u0026#34;string\u0026#34;}, \u0026#34;description\u0026#34;: {\u0026#34;type\u0026#34; : \u0026#34;string\u0026#34;}, \u0026#34;profile_image\u0026#34;:{\u0026#34;type\u0026#34; : \u0026#34;string\u0026#34;}, \u0026#34;birthdate\u0026#34;:{\u0026#34;type\u0026#34; : \u0026#34;date\u0026#34;}, \u0026#34;address\u0026#34;:{\u0026#34;type\u0026#34; : \u0026#34;string\u0026#34;} } } } To ensure mapping is created , just change Action Method to GET and click Request button.\nCreate Record To create record on selected Index and Type, make Action value empty and Action Method as POST after that add following JSON record.\n{ \u0026#34;name\u0026#34;: \u0026#34;Zainul\u0026#34;, \u0026#34;description\u0026#34; : \u0026#34;Software Developer\u0026#34;, \u0026#34;birthdate\u0026#34;: \u0026#34;1985-03-13T00:00:00\u0026#34;, \u0026#34;profile_image\u0026#34; : \u0026#34;image1.png\u0026#34; } And click on Request button. It will index the one record.\nRead Indexed Records To fetch indexed records from Elasticsearch, select Index and Type then Action as _search and Action Method as POST , make query body empty then click on Request button. It will fetch 10 records from selected Index and Type.\nUpdate Records To update value of name field, select Index and Type then Action as _update and Action Method as PUT and add following JSON record in query section then click on Request button.\n{ \u0026#34;script\u0026#34;: \u0026#34;ctx._source.name=\\\u0026#34;Zainul Abedin \\\u0026#34;\u0026#34; } to check record is updated or not, fire search query.\nDelete Records To delete record from selected Index and Type, make Action value empty and select Action Method as DELETE and click on Request button.\nThis is a brief introduction to CRUD operations. in next blog post you will see how to access Elasticsearch via Java Client.\n","permalink":"https://www.zainabed.com/2014/05/getting-started-with-elasticsearch.html/","summary":"Introduction Elasticsearch is open source search system based of Apache Lucene. this is a brief introduction, you can find more information on Elasticsearch Official Site or Wiki.\nWhat are features of Elasticsearch Here are list of features of Elasticsearch.\n Real Time Search and Analytic. Distributed Data (Scales Horizontally) Based on Apache Lucene High Availability Full Text Search JSON Based Documents RESTful API Multi Facets Geo Location Search Open Source  How to install ElasticSearch Download the latest version from Elastic.","title":"Getting Started With Elasticsearch"},{"content":"Introduction This tutorial will help you to create a dynamic web application using power of AngularJs.\nWhat is AngularJs AngularJs is javascript MVC framework (maintained by Google) which molds static HTML application to dynamic web application. That was a brief introduction, you can find more information on Wiki and AngularJS Site.\nAngularJs follows MVC pattern to separate out model from view and manage it by controller.\nSee this image\nGoal of using AngularJs is to convert static HTML template to dynamic (Angular) template.\nHow to convert static template to dynamic (Angular) Template Now consider the following static HTML template which contain list of movies title.\n\u0026lt;h1\u0026gt;Upcoming Movies\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span\u0026gt;Godzilla\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span\u0026gt;Batman vs Superman\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span\u0026gt;Star Wars Episode VII\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; Now lets convert above static HTML template into AngularJs Template by injecting Model-View-Controller by using following steps.\n Create AngularJS module object in javascript which will be the root scope of the AngularJs template. Using above module object create controller function which will hold the model resource (like JSON objects). Within this controller create or access model object (JSON object) using $scope variable. Now Inject module and controller Angularjs tags into view (static HTML template) and access the model object (JSON object) inside view.  Following is blueprint of steps which we are going to perform inside static template.\n NOTE:\n ng-repeat AngularJS tag is used to iterate JSON array {{}} AngularJS tag is used to output content inside HTML   Now let’s create JavaScript code for AngularJs module and controller. We will create a JavaScript file named app.js\n// create module var firstApp = angular.module(\u0026#34;firstApp\u0026#34;,[]); // create controller firstApp.controller(\u0026#34;mainController\u0026#34;, function($scope){ // create model object  $scope.movies = [{title: \u0026#34;Godzilla\u0026#34;},{title: \u0026#34;Batman vs Superman\u0026#34;},{title: \u0026#34;Star Wars Episode VII\u0026#34;}]; }); Now just include this JavaScript file and angular.js file in static HTML template And run the application.\nyou will see the following result\nSource Code You can find source code used in this tutorial on Github page.\n","permalink":"https://www.zainabed.com/2014/05/angularjs-tutorial-getting-started.html/","summary":"Introduction This tutorial will help you to create a dynamic web application using power of AngularJs.\nWhat is AngularJs AngularJs is javascript MVC framework (maintained by Google) which molds static HTML application to dynamic web application. That was a brief introduction, you can find more information on Wiki and AngularJS Site.\nAngularJs follows MVC pattern to separate out model from view and manage it by controller.\nSee this image\nGoal of using AngularJs is to convert static HTML template to dynamic (Angular) template.","title":"Angularjs Tutorial Getting Started"},{"content":"Introduction MongoDB is a No-SQL open source database system that stores information in documents.\nMongoDB was created with excellent performance and accessibility in mind.\nA document is a collection of fields and value pair combinations that are stored in BSON (binary representation of JSON records), which is the native data type in most languages.\nMongoDB uses collections to hold groups of documents.\nNow let’s see the basic operations that can be handled in MongoDB.\n Create Read Update Delete  collectively called the \u0026ldquo;CRUD operation\u0026rdquo;\nCreate Operation MongoDB performs atomic creation operations on single documents. It adds a new document to the selected collection.\ndb.{collection_name}.insert({ field =\u0026gt; value, field =\u0026gt; value, field =\u0026gt; value, }); The value could be a simple datatype or something more complex (document or array).\nThe Create operation always adds the unique identifier of the ObjectId data type to the newly created document.\nObjectId is a 12-byte BSON primarily used to maintain uniqueness in a collection.\nThe following is the byte structure of ObjectId.\n 4 byte for Unix epoch value 3 byte for machine identifier 2 byte for process identifier 3 byte for some random value  Example db.user.insert({ name : \u0026#39;Zainul\u0026#39;, email: \u0026#39;zainabed@gmail.com\u0026#39;, address : \u0026#39;XYZ Address\u0026#39; }) Read Operation The Read operation fetches documents from a single or selected collection. It uses projection and conditions to modify the resulting documents.\nProject is used to retrieve only specific fields of a document, which speeds up the read operation. Condition is used to select a particular document which falls under a given condition.\ndb.{collection}.find( { condition }, { projection } ) We can use limit and sort to limit and order the resulting documents. Note: the order of resulting documents is not defined unless we provide an order for documents.\nExample db.user.find( { name: \u0026#39;Zainul\u0026#39; }, { name : 1, email : 1} ) This command will return a set of documents from a user collection whose name matches the given condition, and will fetch only the name and email. Note: the read operation always returns an ID unless we omit it by using query projection.\nUpdate Operation Update operations modify existing documents or even create new documents. It uses update criteria to isolate documents and update actions to modify the values of selected documents.\ndb.{collection}.update( { update criteria }, { update action }, { update option } ) The Update option tells MongoDB to update multiple documents.\nExample db.user.update( { name : \u0026#39;Zainul\u0026#39; }, { $set : { name : \u0026#39;Abedin\u0026#39; } } )  Note: Use upsert to create a new document if that document does not exist.\n Delete Operation The Delete operation removes single or multiple documents from a selected collection. It uses remove criteria to identify the document that is to be removed.\ndb.{collection}.remove( {remove criteria} ) If the criteria for removal are not defined, then it will remove all the documents.\nExample db.use.remove( { name : \u0026#39;Abedin\u0026#39; } ) Conclusion In this post, you learned about MongoDB\u0026rsquo;s architecture, learned about CRUD operations in MongoDB, and saw some examples of how to use CRUD operations in MongoDB. Hopefully, you now have a clear understanding on how to apply these principles to your MongoDB project.\n","permalink":"https://www.zainabed.com/2013/12/mongodb-getting-started-with-crud.html/","summary":"Introduction MongoDB is a No-SQL open source database system that stores information in documents.\nMongoDB was created with excellent performance and accessibility in mind.\nA document is a collection of fields and value pair combinations that are stored in BSON (binary representation of JSON records), which is the native data type in most languages.\nMongoDB uses collections to hold groups of documents.\nNow let’s see the basic operations that can be handled in MongoDB.","title":"MongoDb Getting Started With Crud"}]